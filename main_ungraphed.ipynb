{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-30T09:07:59.869848Z",
     "start_time": "2025-05-30T09:07:59.844692Z"
    }
   },
   "source": [
    "from curses.ascii import isspace\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ['TF_USE_LEGACY_KERAS'] = '1'\n",
    "import keras\n",
    "import numpy as np\n",
    "from graph import *\n",
    "from encoder import create_encoder\n",
    "import pandas as pd\n",
    "\n",
    "from data_processing import processer\n",
    "from semantic_clustering import *\n",
    "\n",
    "from RepresentationLearner import RepresentationLearner\n",
    "from compute import *\n",
    "from GNN import *\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T09:08:06.243395Z",
     "start_time": "2025-05-30T09:08:04.799129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "num_classes = 10\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n"
   ],
   "id": "1e7d1ec80c4d11fd",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T09:08:08.331038Z",
     "start_time": "2025-05-30T09:08:08.263262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_data = np.concatenate([x_train, x_test])\n",
    "y_data = np.concatenate([y_train, y_test])\n",
    "\n",
    "classes = [\n",
    "    'airplane',\n",
    "    'automobile',\n",
    "    'bird',\n",
    "    'cat',\n",
    "    'deer',\n",
    "    'dog',\n",
    "    'frog',\n",
    "    'horse',\n",
    "    'ship',\n",
    "    'truck',\n",
    "]"
   ],
   "id": "95f4279109cb7ff8",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T09:08:14.663242Z",
     "start_time": "2025-05-30T09:08:14.646052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target_size = 32\n",
    "representation_dims = 512\n",
    "projection_units = 128\n",
    "num_clusters = 28\n",
    "kn = 5\n",
    "tune_encoder_during_clustering = False"
   ],
   "id": "8b6bd48fdaf6d5ff",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T09:08:16.709231Z",
     "start_time": "2025-05-30T09:08:16.002767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_data = x_data.astype('float32')\n",
    "processer.layers[-1].adapt(x_data)"
   ],
   "id": "6d190dad08a6be34",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 59.,  62.,  63.],\n",
       "         [ 43.,  46.,  45.],\n",
       "         [ 50.,  48.,  43.],\n",
       "         ...,\n",
       "         [158., 132., 108.],\n",
       "         [152., 125., 102.],\n",
       "         [148., 124., 103.]],\n",
       "\n",
       "        [[ 16.,  20.,  20.],\n",
       "         [  0.,   0.,   0.],\n",
       "         [ 18.,   8.,   0.],\n",
       "         ...,\n",
       "         [123.,  88.,  55.],\n",
       "         [119.,  83.,  50.],\n",
       "         [122.,  87.,  57.]],\n",
       "\n",
       "        [[ 25.,  24.,  21.],\n",
       "         [ 16.,   7.,   0.],\n",
       "         [ 49.,  27.,   8.],\n",
       "         ...,\n",
       "         [118.,  84.,  50.],\n",
       "         [120.,  84.,  50.],\n",
       "         [109.,  73.,  42.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[208., 170.,  96.],\n",
       "         [201., 153.,  34.],\n",
       "         [198., 161.,  26.],\n",
       "         ...,\n",
       "         [160., 133.,  70.],\n",
       "         [ 56.,  31.,   7.],\n",
       "         [ 53.,  34.,  20.]],\n",
       "\n",
       "        [[180., 139.,  96.],\n",
       "         [173., 123.,  42.],\n",
       "         [186., 144.,  30.],\n",
       "         ...,\n",
       "         [184., 148.,  94.],\n",
       "         [ 97.,  62.,  34.],\n",
       "         [ 83.,  53.,  34.]],\n",
       "\n",
       "        [[177., 144., 116.],\n",
       "         [168., 129.,  94.],\n",
       "         [179., 142.,  87.],\n",
       "         ...,\n",
       "         [216., 184., 140.],\n",
       "         [151., 118.,  84.],\n",
       "         [123.,  92.,  72.]]],\n",
       "\n",
       "\n",
       "       [[[154., 177., 187.],\n",
       "         [126., 137., 136.],\n",
       "         [105., 104.,  95.],\n",
       "         ...,\n",
       "         [ 91.,  95.,  71.],\n",
       "         [ 87.,  90.,  71.],\n",
       "         [ 79.,  81.,  70.]],\n",
       "\n",
       "        [[140., 160., 169.],\n",
       "         [145., 153., 154.],\n",
       "         [125., 125., 118.],\n",
       "         ...,\n",
       "         [ 96.,  99.,  78.],\n",
       "         [ 77.,  80.,  62.],\n",
       "         [ 71.,  73.,  61.]],\n",
       "\n",
       "        [[140., 155., 164.],\n",
       "         [139., 146., 149.],\n",
       "         [115., 115., 112.],\n",
       "         ...,\n",
       "         [ 79.,  82.,  64.],\n",
       "         [ 68.,  70.,  55.],\n",
       "         [ 67.,  69.,  55.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[175., 167., 166.],\n",
       "         [156., 154., 160.],\n",
       "         [154., 160., 170.],\n",
       "         ...,\n",
       "         [ 42.,  34.,  36.],\n",
       "         [ 61.,  53.,  57.],\n",
       "         [ 93.,  83.,  91.]],\n",
       "\n",
       "        [[165., 154., 128.],\n",
       "         [156., 152., 130.],\n",
       "         [159., 161., 142.],\n",
       "         ...,\n",
       "         [103.,  93.,  96.],\n",
       "         [123., 114., 120.],\n",
       "         [131., 121., 131.]],\n",
       "\n",
       "        [[163., 148., 120.],\n",
       "         [158., 148., 122.],\n",
       "         [163., 156., 133.],\n",
       "         ...,\n",
       "         [143., 133., 139.],\n",
       "         [143., 134., 142.],\n",
       "         [143., 133., 144.]]],\n",
       "\n",
       "\n",
       "       [[[255., 255., 255.],\n",
       "         [253., 253., 253.],\n",
       "         [253., 253., 253.],\n",
       "         ...,\n",
       "         [253., 253., 253.],\n",
       "         [253., 253., 253.],\n",
       "         [253., 253., 253.]],\n",
       "\n",
       "        [[255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.]],\n",
       "\n",
       "        [[255., 255., 255.],\n",
       "         [254., 254., 254.],\n",
       "         [254., 254., 254.],\n",
       "         ...,\n",
       "         [254., 254., 254.],\n",
       "         [254., 254., 254.],\n",
       "         [254., 254., 254.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[113., 120., 112.],\n",
       "         [111., 118., 111.],\n",
       "         [105., 112., 106.],\n",
       "         ...,\n",
       "         [ 72.,  81.,  80.],\n",
       "         [ 72.,  80.,  79.],\n",
       "         [ 72.,  80.,  79.]],\n",
       "\n",
       "        [[111., 118., 110.],\n",
       "         [104., 111., 104.],\n",
       "         [ 99., 106.,  98.],\n",
       "         ...,\n",
       "         [ 68.,  75.,  73.],\n",
       "         [ 70.,  76.,  75.],\n",
       "         [ 78.,  84.,  82.]],\n",
       "\n",
       "        [[106., 113., 105.],\n",
       "         [ 99., 106.,  98.],\n",
       "         [ 95., 102.,  94.],\n",
       "         ...,\n",
       "         [ 78.,  85.,  83.],\n",
       "         [ 79.,  85.,  83.],\n",
       "         [ 80.,  86.,  84.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 20.,  15.,  12.],\n",
       "         [ 19.,  14.,  11.],\n",
       "         [ 15.,  14.,  11.],\n",
       "         ...,\n",
       "         [ 10.,   9.,   7.],\n",
       "         [ 12.,  11.,   9.],\n",
       "         [ 13.,  12.,  10.]],\n",
       "\n",
       "        [[ 21.,  16.,  13.],\n",
       "         [ 20.,  16.,  13.],\n",
       "         [ 18.,  17.,  12.],\n",
       "         ...,\n",
       "         [ 10.,   9.,   7.],\n",
       "         [ 10.,   9.,   7.],\n",
       "         [ 12.,  11.,   9.]],\n",
       "\n",
       "        [[ 21.,  16.,  13.],\n",
       "         [ 21.,  17.,  12.],\n",
       "         [ 20.,  18.,  11.],\n",
       "         ...,\n",
       "         [ 12.,  11.,   9.],\n",
       "         [ 12.,  11.,   9.],\n",
       "         [ 13.,  12.,  10.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 33.,  25.,  13.],\n",
       "         [ 34.,  26.,  15.],\n",
       "         [ 34.,  26.,  15.],\n",
       "         ...,\n",
       "         [ 28.,  25.,  52.],\n",
       "         [ 29.,  25.,  58.],\n",
       "         [ 23.,  20.,  42.]],\n",
       "\n",
       "        [[ 33.,  25.,  14.],\n",
       "         [ 34.,  26.,  15.],\n",
       "         [ 34.,  26.,  15.],\n",
       "         ...,\n",
       "         [ 27.,  24.,  52.],\n",
       "         [ 27.,  24.,  56.],\n",
       "         [ 25.,  22.,  47.]],\n",
       "\n",
       "        [[ 31.,  23.,  12.],\n",
       "         [ 32.,  24.,  13.],\n",
       "         [ 33.,  25.,  14.],\n",
       "         ...,\n",
       "         [ 24.,  23.,  50.],\n",
       "         [ 26.,  23.,  53.],\n",
       "         [ 25.,  20.,  47.]]],\n",
       "\n",
       "\n",
       "       [[[ 25.,  40.,  12.],\n",
       "         [ 15.,  36.,   3.],\n",
       "         [ 23.,  41.,  18.],\n",
       "         ...,\n",
       "         [ 61.,  82.,  78.],\n",
       "         [ 92., 113., 112.],\n",
       "         [ 75.,  89.,  92.]],\n",
       "\n",
       "        [[ 12.,  25.,   6.],\n",
       "         [ 20.,  37.,   7.],\n",
       "         [ 24.,  36.,  15.],\n",
       "         ...,\n",
       "         [115., 134., 138.],\n",
       "         [149., 168., 177.],\n",
       "         [104., 117., 131.]],\n",
       "\n",
       "        [[ 12.,  25.,  11.],\n",
       "         [ 15.,  29.,   6.],\n",
       "         [ 34.,  40.,  24.],\n",
       "         ...,\n",
       "         [154., 172., 182.],\n",
       "         [157., 175., 192.],\n",
       "         [116., 129., 151.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[100., 129.,  81.],\n",
       "         [103., 132.,  84.],\n",
       "         [104., 134.,  86.],\n",
       "         ...,\n",
       "         [ 97., 128.,  84.],\n",
       "         [ 98., 126.,  84.],\n",
       "         [ 91., 121.,  79.]],\n",
       "\n",
       "        [[103., 132.,  83.],\n",
       "         [104., 131.,  83.],\n",
       "         [107., 135.,  87.],\n",
       "         ...,\n",
       "         [101., 132.,  87.],\n",
       "         [ 99., 127.,  84.],\n",
       "         [ 92., 121.,  79.]],\n",
       "\n",
       "        [[ 95., 126.,  78.],\n",
       "         [ 95., 123.,  76.],\n",
       "         [101., 128.,  81.],\n",
       "         ...,\n",
       "         [ 93., 124.,  80.],\n",
       "         [ 95., 123.,  81.],\n",
       "         [ 92., 120.,  80.]]],\n",
       "\n",
       "\n",
       "       [[[ 73.,  78.,  75.],\n",
       "         [ 98., 103., 113.],\n",
       "         [ 99., 106., 114.],\n",
       "         ...,\n",
       "         [135., 150., 152.],\n",
       "         [135., 149., 154.],\n",
       "         [203., 215., 223.]],\n",
       "\n",
       "        [[ 69.,  73.,  70.],\n",
       "         [ 84.,  89.,  97.],\n",
       "         [ 68.,  75.,  81.],\n",
       "         ...,\n",
       "         [ 85.,  95.,  89.],\n",
       "         [ 71.,  82.,  80.],\n",
       "         [120., 133., 135.]],\n",
       "\n",
       "        [[ 69.,  73.,  70.],\n",
       "         [ 90.,  95., 100.],\n",
       "         [ 62.,  71.,  74.],\n",
       "         ...,\n",
       "         [ 74.,  81.,  70.],\n",
       "         [ 53.,  62.,  54.],\n",
       "         [ 62.,  74.,  69.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[123., 128.,  96.],\n",
       "         [132., 132., 102.],\n",
       "         [129., 128., 100.],\n",
       "         ...,\n",
       "         [108., 107.,  88.],\n",
       "         [ 62.,  60.,  55.],\n",
       "         [ 27.,  27.,  28.]],\n",
       "\n",
       "        [[115., 121.,  91.],\n",
       "         [123., 124.,  95.],\n",
       "         [129., 126.,  99.],\n",
       "         ...,\n",
       "         [115., 116.,  94.],\n",
       "         [ 66.,  65.,  59.],\n",
       "         [ 27.,  27.,  27.]],\n",
       "\n",
       "        [[116., 120.,  90.],\n",
       "         [121., 122.,  94.],\n",
       "         [129., 128., 101.],\n",
       "         ...,\n",
       "         [116., 115.,  94.],\n",
       "         [ 68.,  65.,  58.],\n",
       "         [ 27.,  26.,  26.]]]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T09:08:20.140709Z",
     "start_time": "2025-05-30T09:08:19.222673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "encoder = create_encoder(\n",
    "    representation_dims\n",
    ")"
   ],
   "id": "35f134e532a81faa",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T10:03:18.613369Z",
     "start_time": "2025-05-30T09:08:21.745779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "representation_learner = RepresentationLearner(encoder, projection_units, num_augmentations=4)\n",
    "\n",
    "lr_scheduler = keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=0.001,\n",
    "    decay_steps=500,\n",
    "    alpha=0.1\n",
    ")\n",
    "optimizer = keras.optimizers.AdamW(learning_rate=lr_scheduler, weight_decay=0.0001)\n",
    "\n",
    "representation_learner.compile(\n",
    "    optimizer=optimizer,\n",
    "    jit_compile=False,\n",
    ")\n",
    "\n",
    "history = representation_learner.fit(\n",
    "    x=x_data,\n",
    "    batch_size=512,\n",
    "    epochs=50\n",
    ")\n",
    "\n"
   ],
   "id": "6dafdceb4a59ef60",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1748596135.843657    1778 cuda_dnn.cc:529] Loaded cuDNN version 90501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m110s\u001B[0m 573ms/step - loss: 29.0362\n",
      "Epoch 2/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m63s\u001B[0m 536ms/step - loss: 28.2116\n",
      "Epoch 3/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m63s\u001B[0m 536ms/step - loss: 27.9178\n",
      "Epoch 4/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m64s\u001B[0m 542ms/step - loss: 27.7095\n",
      "Epoch 5/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m64s\u001B[0m 544ms/step - loss: 27.6018\n",
      "Epoch 6/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m61s\u001B[0m 521ms/step - loss: 27.5573\n",
      "Epoch 7/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m64s\u001B[0m 546ms/step - loss: 27.5222\n",
      "Epoch 8/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m64s\u001B[0m 546ms/step - loss: 27.4922\n",
      "Epoch 9/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m64s\u001B[0m 543ms/step - loss: 27.4728\n",
      "Epoch 10/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m65s\u001B[0m 552ms/step - loss: 27.4525\n",
      "Epoch 11/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m62s\u001B[0m 523ms/step - loss: 27.4290\n",
      "Epoch 12/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m67s\u001B[0m 570ms/step - loss: 27.4124\n",
      "Epoch 13/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m88s\u001B[0m 545ms/step - loss: 27.3946\n",
      "Epoch 14/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m65s\u001B[0m 548ms/step - loss: 27.3822\n",
      "Epoch 15/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m62s\u001B[0m 525ms/step - loss: 27.3726\n",
      "Epoch 16/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m65s\u001B[0m 551ms/step - loss: 27.3649\n",
      "Epoch 17/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m65s\u001B[0m 549ms/step - loss: 27.3477\n",
      "Epoch 18/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m64s\u001B[0m 547ms/step - loss: 27.3326\n",
      "Epoch 19/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m65s\u001B[0m 547ms/step - loss: 27.3243\n",
      "Epoch 20/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m64s\u001B[0m 547ms/step - loss: 27.3152\n",
      "Epoch 21/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m62s\u001B[0m 525ms/step - loss: 27.3091\n",
      "Epoch 22/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m64s\u001B[0m 547ms/step - loss: 27.3015\n",
      "Epoch 23/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m66s\u001B[0m 559ms/step - loss: 27.2942\n",
      "Epoch 24/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m61s\u001B[0m 517ms/step - loss: 27.2881\n",
      "Epoch 25/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m64s\u001B[0m 544ms/step - loss: 27.2799\n",
      "Epoch 26/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m65s\u001B[0m 547ms/step - loss: 27.2808\n",
      "Epoch 27/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m65s\u001B[0m 548ms/step - loss: 27.2690\n",
      "Epoch 28/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m65s\u001B[0m 548ms/step - loss: 27.2624\n",
      "Epoch 29/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m77s\u001B[0m 654ms/step - loss: 27.2457\n",
      "Epoch 30/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m64s\u001B[0m 544ms/step - loss: 27.2408\n",
      "Epoch 31/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m65s\u001B[0m 554ms/step - loss: 27.2298\n",
      "Epoch 32/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m65s\u001B[0m 553ms/step - loss: 27.2235\n",
      "Epoch 33/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m65s\u001B[0m 551ms/step - loss: 27.2211\n",
      "Epoch 34/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m66s\u001B[0m 559ms/step - loss: 27.2117\n",
      "Epoch 35/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m61s\u001B[0m 521ms/step - loss: 27.2092\n",
      "Epoch 36/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m65s\u001B[0m 549ms/step - loss: 27.2017\n",
      "Epoch 37/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m65s\u001B[0m 553ms/step - loss: 27.2007\n",
      "Epoch 38/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m65s\u001B[0m 552ms/step - loss: 27.1903\n",
      "Epoch 39/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m66s\u001B[0m 557ms/step - loss: 27.1856\n",
      "Epoch 40/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m66s\u001B[0m 561ms/step - loss: 27.1824\n",
      "Epoch 41/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m62s\u001B[0m 524ms/step - loss: 27.1779\n",
      "Epoch 42/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m65s\u001B[0m 526ms/step - loss: 27.1736\n",
      "Epoch 43/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m65s\u001B[0m 553ms/step - loss: 27.1718\n",
      "Epoch 44/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m65s\u001B[0m 549ms/step - loss: 27.1681\n",
      "Epoch 45/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m65s\u001B[0m 549ms/step - loss: 27.1686\n",
      "Epoch 46/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m65s\u001B[0m 548ms/step - loss: 27.1645\n",
      "Epoch 47/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m62s\u001B[0m 525ms/step - loss: 27.1601\n",
      "Epoch 48/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m64s\u001B[0m 547ms/step - loss: 27.1572\n",
      "Epoch 49/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m65s\u001B[0m 550ms/step - loss: 27.1566\n",
      "Epoch 50/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m65s\u001B[0m 551ms/step - loss: 27.1535\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T10:15:34.807600Z",
     "start_time": "2025-05-30T10:15:27.061307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 500\n",
    "feature_vectors = encoder.predict(x_data, batch_size=batch_size, verbose=1)\n",
    "feature_vectors = keras.utils.normalize(feature_vectors)\n"
   ],
   "id": "bd29dd5b05fd88a3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1748600128.484691    1776 service.cc:152] XLA service 0x7f69a4c303c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1748600128.484726    1776 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2025-05-30 11:15:28.529490: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-05-30 11:15:29.551994: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1483', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-05-30 11:15:29.559885: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1483', 3312 bytes spill stores, 3016 bytes spill loads\n",
      "\n",
      "2025-05-30 11:15:29.595081: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1483_0', 108 bytes spill stores, 108 bytes spill loads\n",
      "\n",
      "2025-05-30 11:15:29.626918: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1483', 64 bytes spill stores, 64 bytes spill loads\n",
      "\n",
      "2025-05-30 11:15:29.651608: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1483', 64 bytes spill stores, 64 bytes spill loads\n",
      "\n",
      "2025-05-30 11:15:29.652067: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1483_0', 1432 bytes spill stores, 1148 bytes spill loads\n",
      "\n",
      "2025-05-30 11:15:29.661908: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1483', 604 bytes spill stores, 604 bytes spill loads\n",
      "\n",
      "2025-05-30 11:15:29.666382: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1483', 476 bytes spill stores, 476 bytes spill loads\n",
      "\n",
      "2025-05-30 11:15:29.671978: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1483', 116 bytes spill stores, 116 bytes spill loads\n",
      "\n",
      "2025-05-30 11:15:29.688384: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1483', 844 bytes spill stores, 844 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m 13/120\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m1s\u001B[0m 15ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1748600132.928119    1776 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m120/120\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 15ms/step\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T10:15:43.560726Z",
     "start_time": "2025-05-30T10:15:38.815783Z"
    }
   },
   "cell_type": "code",
   "source": "knns = compute_knn(feature_vectors, batch_size=batch_size, kn=kn)\n",
   "id": "cc2e69094338a490",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [00:04<00:00, 25.38it/s]\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-05-30T10:15:49.858888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for layer in encoder.layers:\n",
    "    layer.trainable = tune_encoder_during_clustering\n",
    "\n",
    "clustering_model = create_clustering_model(encoder, num_clusters, input_shape, name='clustering')\n",
    "clustering_learner = create_clustering_learner(clustering_model, input_shape)\n",
    "\n",
    "losses = [ClustersEntropyLoss(), ClustersEntropyLoss(entropy_loss_weight=5)]\n",
    "\n",
    "inputs = {\"anchor\": x_data, 'neighbours': tf.gather(x_data, knns)}\n",
    "labels = [np.ones(shape=(x_data.shape[0], kn)), np.ones(shape=(x_data.shape[0], kn))]\n",
    "\n",
    "clustering_learner.compile(\n",
    "    optimizer=keras.optimizers.AdamW(learning_rate=0.0005, weight_decay=0.0001),\n",
    "    loss=losses,\n",
    "    jit_compile=False,\n",
    ")\n",
    "\n",
    "clustering_learner.fit(\n",
    "    x=inputs,\n",
    "    y=labels,\n",
    "    batch_size=512,\n",
    "    epochs=50\n",
    ")\n",
    "\n"
   ],
   "id": "e6ab855abe9412d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 11:15:59.550246: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.80GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m  1/118\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m15:38\u001B[0m 8s/step - clustering_loss: 0.0860 - loss: 0.9303 - simlarity_loss: 0.8444"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 11:15:59.837096: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.64GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-05-30 11:15:59.895810: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.63GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m 56/118\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m8s\u001B[0m 130ms/step - clustering_loss: 0.1272 - loss: 0.6447 - simlarity_loss: 0.5175"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T17:02:59.235263Z",
     "start_time": "2025-05-29T17:02:54.560260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "clustering_probabilitiys = clustering_model.predict(x_data, batch_size=batch_size)\n",
    "cluster_assigment = keras.ops.argmax(clustering_probabilitiys, axis=-1).numpy()\n",
    "\n",
    "cluster_confidence = keras.ops.max(clustering_probabilitiys, axis=-1).numpy()"
   ],
   "id": "3b8ed9f163a25349",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m120/120\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 24ms/step\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T17:02:59.294340Z",
     "start_time": "2025-05-29T17:02:59.253921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "clusters = defaultdict(list)\n",
    "\n",
    "for idx, c in enumerate(cluster_assigment):\n",
    "    clusters[c].append((idx, cluster_confidence[idx]))\n",
    "\n",
    "non_empty_clusters = defaultdict(list)\n",
    "\n",
    "for c in clusters.keys():\n",
    "    if clusters[c]:\n",
    "        non_empty_clusters[c] = clusters[c]\n",
    "\n",
    "for c in range(num_clusters):\n",
    "    print(f\"Cluster {c}:  {len(clusters[c])}\")"
   ],
   "id": "98d5416c4f676c46",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0:  1488\n",
      "Cluster 1:  1308\n",
      "Cluster 2:  1889\n",
      "Cluster 3:  1854\n",
      "Cluster 4:  1234\n",
      "Cluster 5:  1885\n",
      "Cluster 6:  2097\n",
      "Cluster 7:  1604\n",
      "Cluster 8:  2051\n",
      "Cluster 9:  2144\n",
      "Cluster 10:  1499\n",
      "Cluster 11:  1520\n",
      "Cluster 12:  1299\n",
      "Cluster 13:  1674\n",
      "Cluster 14:  1299\n",
      "Cluster 15:  1962\n",
      "Cluster 16:  8275\n",
      "Cluster 17:  1851\n",
      "Cluster 18:  1806\n",
      "Cluster 19:  1451\n",
      "Cluster 20:  1832\n",
      "Cluster 21:  1371\n",
      "Cluster 22:  1771\n",
      "Cluster 23:  8962\n",
      "Cluster 24:  1626\n",
      "Cluster 25:  2003\n",
      "Cluster 26:  767\n",
      "Cluster 27:  1478\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T17:03:01.602712Z",
     "start_time": "2025-05-29T17:02:59.358921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "k = 5\n",
    "cluster_knns = {}\n",
    "\n",
    "for c, members in non_empty_clusters.items():\n",
    "    indices = [idx for idx, _ in members]\n",
    "    if len(indices) < k + 1:\n",
    "\n",
    "        continue\n",
    "\n",
    "    clutser_features = feature_vectors[indices]\n",
    "    nbrs = NearestNeighbors(n_neighbors=k + 1, algorithm='auto').fit(clutser_features)\n",
    "\n",
    "    distances, n_indices = nbrs.kneighbors(clutser_features)\n",
    "\n",
    "    knns = [ [indices[n] for n in n[1:]] for n in n_indices]\n",
    "\n",
    "    cluster_knns[c] = dict(zip(indices, knns))\n",
    "\n"
   ],
   "id": "8962550aac20e242",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T17:03:02.767409Z",
     "start_time": "2025-05-29T17:03:02.677295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from scipy.sparse import lil_matrix, issparse, csr_matrix\n",
    "\n",
    "num_nodes = feature_vectors.shape[0]\n",
    "adjencency = lil_matrix((num_nodes, num_nodes))\n",
    "\n",
    "for cluster in cluster_knns.values():\n",
    "    for node_idx, knn_lisy in cluster.items():\n",
    "        for neighbor in knn_lisy:\n",
    "            adjencency[node_idx, neighbor] = 1\n",
    "            adjencency[neighbor, node_idx] = 2"
   ],
   "id": "f6a4eb062ad2ae8d",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T17:03:04.864029Z",
     "start_time": "2025-05-29T17:03:02.890716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from scipy.sparse import csr_matrix, issparse\n",
    "\n",
    "def graph_augmented(features, adjencency):\n",
    "    if not issparse(adjencency):\n",
    "        adj_aug = csr_matrix(adjencency)\n",
    "    else:\n",
    "        adj_aug = adjencency.copy()\n",
    "\n",
    "    mask = np.random.rand(*adj_aug.shape) < 0.1\n",
    "    mask_sparse = csr_matrix(mask)\n",
    "\n",
    "    adj_aug = adj_aug.multiply(mask_sparse)\n",
    "\n",
    "    feat_aug = features.copy()\n",
    "    mask_features = np.random.rand(*feat_aug.shape) < 0.1\n",
    "    feat_aug[~mask_features] = 0\n",
    "\n",
    "    return adj_aug, feat_aug"
   ],
   "id": "1eda1c04b3b9e611",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T17:03:06.945193Z",
     "start_time": "2025-05-29T17:03:06.917765Z"
    }
   },
   "cell_type": "code",
   "source": "generator = GraphDataGenerator(feature_vectors, adjencency, augmented_fn=graph_augmented)",
   "id": "e9b2b1939c6b3524",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T17:03:07.210956Z",
     "start_time": "2025-05-29T17:03:07.170166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "feature_dims = feature_vectors.shape[0]\n",
    "proj_dims = 64\n",
    "output_dims = 64\n",
    "hidden_dims = 128\n",
    "\n",
    "encoder = create_gnn_encoder(feature_dims, hidden_dims, proj_dims)\n",
    "projector = create_projector(proj_dims, output_dims)\n",
    "\n",
    "model = SimSiamGNN(encoder, projector)\n"
   ],
   "id": "a8986a2a15fe09d1",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T17:03:08.287331Z",
     "start_time": "2025-05-29T17:03:08.197894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3)\n",
    ")"
   ],
   "id": "66ed504160f7e1d0",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T17:03:08.424161Z",
     "start_time": "2025-05-29T17:03:08.374705Z"
    }
   },
   "cell_type": "code",
   "source": "model.fit(generator, epochs=50)",
   "id": "db69acd195a177bb",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T17:03:08.546761Z",
     "start_time": "2025-05-29T17:03:08.492929Z"
    }
   },
   "cell_type": "code",
   "source": "model.save('first.keras')",
   "id": "d5894c88c6415eac",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T17:03:09.065023Z",
     "start_time": "2025-05-29T17:03:09.037566Z"
    }
   },
   "cell_type": "code",
   "source": "train_labels = keras.utils.to_categorical(train_labels, num_classes=num_classes)",
   "id": "1fe99fc791a1d24d",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T17:03:09.477455Z",
     "start_time": "2025-05-29T17:03:09.456084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_indices = tf.convert_to_tensor(train_indices, dtype=tf.int32)\n",
    "train_labels = tf.convert_to_tensor(train_labels, dtype=tf.float32)"
   ],
   "id": "b63edcfe129eb16",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model.save('completed_model.h5')",
   "id": "4aafb5adc8f7cb75"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
