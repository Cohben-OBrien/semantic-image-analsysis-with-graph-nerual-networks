{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T13:53:58.885631Z",
     "start_time": "2025-05-20T13:53:58.840016Z"
    }
   },
   "source": [
    "from h5py.h5i import DATASET\n",
    "from sympy.physics.secondquant import InnerProduct\n",
    "from tensorflow.python.keras.legacy_tf_layers.core import dense\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ['TF_USE_LEGACY_KERAS'] = '1'\n",
    "import keras\n",
    "import numpy as np\n",
    "from graph import *\n",
    "from encoder import create_encoder\n",
    "\n",
    "\n",
    "from data_processing import processer\n",
    "import tensorflow_gnn as tfgnn\n",
    "from tensorflow_gnn.keras.layers import GraphUpdate, SimpleConv\n",
    "\n",
    "from RepresentationLearner import RepresentationLearner\n",
    "from compute import *\n",
    "from GNN import *\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T13:54:00.613184Z",
     "start_time": "2025-05-20T13:53:58.905071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "num_classes = 10\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n"
   ],
   "id": "1e7d1ec80c4d11fd",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T13:54:00.744300Z",
     "start_time": "2025-05-20T13:54:00.623194Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_data = np.concatenate([x_train, x_test])\n",
    "y_data = np.concatenate([y_train, y_test])\n",
    "\n",
    "classes = [\n",
    "    'airplane',\n",
    "    'automobile',\n",
    "    'bird',\n",
    "    'cat',\n",
    "    'deer',\n",
    "    'dog',\n",
    "    'frog',\n",
    "    'horse',\n",
    "    'ship',\n",
    "    'truck',\n",
    "]"
   ],
   "id": "95f4279109cb7ff8",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T13:54:00.779196Z",
     "start_time": "2025-05-20T13:54:00.754302Z"
    }
   },
   "cell_type": "code",
   "source": "x_data",
   "id": "c9f95f47ed6c7885",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 59,  62,  63],\n",
       "         [ 43,  46,  45],\n",
       "         [ 50,  48,  43],\n",
       "         ...,\n",
       "         [158, 132, 108],\n",
       "         [152, 125, 102],\n",
       "         [148, 124, 103]],\n",
       "\n",
       "        [[ 16,  20,  20],\n",
       "         [  0,   0,   0],\n",
       "         [ 18,   8,   0],\n",
       "         ...,\n",
       "         [123,  88,  55],\n",
       "         [119,  83,  50],\n",
       "         [122,  87,  57]],\n",
       "\n",
       "        [[ 25,  24,  21],\n",
       "         [ 16,   7,   0],\n",
       "         [ 49,  27,   8],\n",
       "         ...,\n",
       "         [118,  84,  50],\n",
       "         [120,  84,  50],\n",
       "         [109,  73,  42]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[208, 170,  96],\n",
       "         [201, 153,  34],\n",
       "         [198, 161,  26],\n",
       "         ...,\n",
       "         [160, 133,  70],\n",
       "         [ 56,  31,   7],\n",
       "         [ 53,  34,  20]],\n",
       "\n",
       "        [[180, 139,  96],\n",
       "         [173, 123,  42],\n",
       "         [186, 144,  30],\n",
       "         ...,\n",
       "         [184, 148,  94],\n",
       "         [ 97,  62,  34],\n",
       "         [ 83,  53,  34]],\n",
       "\n",
       "        [[177, 144, 116],\n",
       "         [168, 129,  94],\n",
       "         [179, 142,  87],\n",
       "         ...,\n",
       "         [216, 184, 140],\n",
       "         [151, 118,  84],\n",
       "         [123,  92,  72]]],\n",
       "\n",
       "\n",
       "       [[[154, 177, 187],\n",
       "         [126, 137, 136],\n",
       "         [105, 104,  95],\n",
       "         ...,\n",
       "         [ 91,  95,  71],\n",
       "         [ 87,  90,  71],\n",
       "         [ 79,  81,  70]],\n",
       "\n",
       "        [[140, 160, 169],\n",
       "         [145, 153, 154],\n",
       "         [125, 125, 118],\n",
       "         ...,\n",
       "         [ 96,  99,  78],\n",
       "         [ 77,  80,  62],\n",
       "         [ 71,  73,  61]],\n",
       "\n",
       "        [[140, 155, 164],\n",
       "         [139, 146, 149],\n",
       "         [115, 115, 112],\n",
       "         ...,\n",
       "         [ 79,  82,  64],\n",
       "         [ 68,  70,  55],\n",
       "         [ 67,  69,  55]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[175, 167, 166],\n",
       "         [156, 154, 160],\n",
       "         [154, 160, 170],\n",
       "         ...,\n",
       "         [ 42,  34,  36],\n",
       "         [ 61,  53,  57],\n",
       "         [ 93,  83,  91]],\n",
       "\n",
       "        [[165, 154, 128],\n",
       "         [156, 152, 130],\n",
       "         [159, 161, 142],\n",
       "         ...,\n",
       "         [103,  93,  96],\n",
       "         [123, 114, 120],\n",
       "         [131, 121, 131]],\n",
       "\n",
       "        [[163, 148, 120],\n",
       "         [158, 148, 122],\n",
       "         [163, 156, 133],\n",
       "         ...,\n",
       "         [143, 133, 139],\n",
       "         [143, 134, 142],\n",
       "         [143, 133, 144]]],\n",
       "\n",
       "\n",
       "       [[[255, 255, 255],\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253],\n",
       "         ...,\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254],\n",
       "         ...,\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[113, 120, 112],\n",
       "         [111, 118, 111],\n",
       "         [105, 112, 106],\n",
       "         ...,\n",
       "         [ 72,  81,  80],\n",
       "         [ 72,  80,  79],\n",
       "         [ 72,  80,  79]],\n",
       "\n",
       "        [[111, 118, 110],\n",
       "         [104, 111, 104],\n",
       "         [ 99, 106,  98],\n",
       "         ...,\n",
       "         [ 68,  75,  73],\n",
       "         [ 70,  76,  75],\n",
       "         [ 78,  84,  82]],\n",
       "\n",
       "        [[106, 113, 105],\n",
       "         [ 99, 106,  98],\n",
       "         [ 95, 102,  94],\n",
       "         ...,\n",
       "         [ 78,  85,  83],\n",
       "         [ 79,  85,  83],\n",
       "         [ 80,  86,  84]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 20,  15,  12],\n",
       "         [ 19,  14,  11],\n",
       "         [ 15,  14,  11],\n",
       "         ...,\n",
       "         [ 10,   9,   7],\n",
       "         [ 12,  11,   9],\n",
       "         [ 13,  12,  10]],\n",
       "\n",
       "        [[ 21,  16,  13],\n",
       "         [ 20,  16,  13],\n",
       "         [ 18,  17,  12],\n",
       "         ...,\n",
       "         [ 10,   9,   7],\n",
       "         [ 10,   9,   7],\n",
       "         [ 12,  11,   9]],\n",
       "\n",
       "        [[ 21,  16,  13],\n",
       "         [ 21,  17,  12],\n",
       "         [ 20,  18,  11],\n",
       "         ...,\n",
       "         [ 12,  11,   9],\n",
       "         [ 12,  11,   9],\n",
       "         [ 13,  12,  10]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 33,  25,  13],\n",
       "         [ 34,  26,  15],\n",
       "         [ 34,  26,  15],\n",
       "         ...,\n",
       "         [ 28,  25,  52],\n",
       "         [ 29,  25,  58],\n",
       "         [ 23,  20,  42]],\n",
       "\n",
       "        [[ 33,  25,  14],\n",
       "         [ 34,  26,  15],\n",
       "         [ 34,  26,  15],\n",
       "         ...,\n",
       "         [ 27,  24,  52],\n",
       "         [ 27,  24,  56],\n",
       "         [ 25,  22,  47]],\n",
       "\n",
       "        [[ 31,  23,  12],\n",
       "         [ 32,  24,  13],\n",
       "         [ 33,  25,  14],\n",
       "         ...,\n",
       "         [ 24,  23,  50],\n",
       "         [ 26,  23,  53],\n",
       "         [ 25,  20,  47]]],\n",
       "\n",
       "\n",
       "       [[[ 25,  40,  12],\n",
       "         [ 15,  36,   3],\n",
       "         [ 23,  41,  18],\n",
       "         ...,\n",
       "         [ 61,  82,  78],\n",
       "         [ 92, 113, 112],\n",
       "         [ 75,  89,  92]],\n",
       "\n",
       "        [[ 12,  25,   6],\n",
       "         [ 20,  37,   7],\n",
       "         [ 24,  36,  15],\n",
       "         ...,\n",
       "         [115, 134, 138],\n",
       "         [149, 168, 177],\n",
       "         [104, 117, 131]],\n",
       "\n",
       "        [[ 12,  25,  11],\n",
       "         [ 15,  29,   6],\n",
       "         [ 34,  40,  24],\n",
       "         ...,\n",
       "         [154, 172, 182],\n",
       "         [157, 175, 192],\n",
       "         [116, 129, 151]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[100, 129,  81],\n",
       "         [103, 132,  84],\n",
       "         [104, 134,  86],\n",
       "         ...,\n",
       "         [ 97, 128,  84],\n",
       "         [ 98, 126,  84],\n",
       "         [ 91, 121,  79]],\n",
       "\n",
       "        [[103, 132,  83],\n",
       "         [104, 131,  83],\n",
       "         [107, 135,  87],\n",
       "         ...,\n",
       "         [101, 132,  87],\n",
       "         [ 99, 127,  84],\n",
       "         [ 92, 121,  79]],\n",
       "\n",
       "        [[ 95, 126,  78],\n",
       "         [ 95, 123,  76],\n",
       "         [101, 128,  81],\n",
       "         ...,\n",
       "         [ 93, 124,  80],\n",
       "         [ 95, 123,  81],\n",
       "         [ 92, 120,  80]]],\n",
       "\n",
       "\n",
       "       [[[ 73,  78,  75],\n",
       "         [ 98, 103, 113],\n",
       "         [ 99, 106, 114],\n",
       "         ...,\n",
       "         [135, 150, 152],\n",
       "         [135, 149, 154],\n",
       "         [203, 215, 223]],\n",
       "\n",
       "        [[ 69,  73,  70],\n",
       "         [ 84,  89,  97],\n",
       "         [ 68,  75,  81],\n",
       "         ...,\n",
       "         [ 85,  95,  89],\n",
       "         [ 71,  82,  80],\n",
       "         [120, 133, 135]],\n",
       "\n",
       "        [[ 69,  73,  70],\n",
       "         [ 90,  95, 100],\n",
       "         [ 62,  71,  74],\n",
       "         ...,\n",
       "         [ 74,  81,  70],\n",
       "         [ 53,  62,  54],\n",
       "         [ 62,  74,  69]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[123, 128,  96],\n",
       "         [132, 132, 102],\n",
       "         [129, 128, 100],\n",
       "         ...,\n",
       "         [108, 107,  88],\n",
       "         [ 62,  60,  55],\n",
       "         [ 27,  27,  28]],\n",
       "\n",
       "        [[115, 121,  91],\n",
       "         [123, 124,  95],\n",
       "         [129, 126,  99],\n",
       "         ...,\n",
       "         [115, 116,  94],\n",
       "         [ 66,  65,  59],\n",
       "         [ 27,  27,  27]],\n",
       "\n",
       "        [[116, 120,  90],\n",
       "         [121, 122,  94],\n",
       "         [129, 128, 101],\n",
       "         ...,\n",
       "         [116, 115,  94],\n",
       "         [ 68,  65,  58],\n",
       "         [ 27,  26,  26]]]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T13:54:00.835001Z",
     "start_time": "2025-05-20T13:54:00.811899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target_size = 32\n",
    "representation_dims = 512\n",
    "projection_units = 128\n",
    "num_clusters = 28\n",
    "kn = 5\n",
    "tune_encoder_during_clustering = False"
   ],
   "id": "8b6bd48fdaf6d5ff",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T13:54:01.786527Z",
     "start_time": "2025-05-20T13:54:00.862010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_data = x_data.astype('float32')\n",
    "processer.layers[-1].adapt(x_data)\n",
    "x_data"
   ],
   "id": "6d190dad08a6be34",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 59.,  62.,  63.],\n",
       "         [ 43.,  46.,  45.],\n",
       "         [ 50.,  48.,  43.],\n",
       "         ...,\n",
       "         [158., 132., 108.],\n",
       "         [152., 125., 102.],\n",
       "         [148., 124., 103.]],\n",
       "\n",
       "        [[ 16.,  20.,  20.],\n",
       "         [  0.,   0.,   0.],\n",
       "         [ 18.,   8.,   0.],\n",
       "         ...,\n",
       "         [123.,  88.,  55.],\n",
       "         [119.,  83.,  50.],\n",
       "         [122.,  87.,  57.]],\n",
       "\n",
       "        [[ 25.,  24.,  21.],\n",
       "         [ 16.,   7.,   0.],\n",
       "         [ 49.,  27.,   8.],\n",
       "         ...,\n",
       "         [118.,  84.,  50.],\n",
       "         [120.,  84.,  50.],\n",
       "         [109.,  73.,  42.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[208., 170.,  96.],\n",
       "         [201., 153.,  34.],\n",
       "         [198., 161.,  26.],\n",
       "         ...,\n",
       "         [160., 133.,  70.],\n",
       "         [ 56.,  31.,   7.],\n",
       "         [ 53.,  34.,  20.]],\n",
       "\n",
       "        [[180., 139.,  96.],\n",
       "         [173., 123.,  42.],\n",
       "         [186., 144.,  30.],\n",
       "         ...,\n",
       "         [184., 148.,  94.],\n",
       "         [ 97.,  62.,  34.],\n",
       "         [ 83.,  53.,  34.]],\n",
       "\n",
       "        [[177., 144., 116.],\n",
       "         [168., 129.,  94.],\n",
       "         [179., 142.,  87.],\n",
       "         ...,\n",
       "         [216., 184., 140.],\n",
       "         [151., 118.,  84.],\n",
       "         [123.,  92.,  72.]]],\n",
       "\n",
       "\n",
       "       [[[154., 177., 187.],\n",
       "         [126., 137., 136.],\n",
       "         [105., 104.,  95.],\n",
       "         ...,\n",
       "         [ 91.,  95.,  71.],\n",
       "         [ 87.,  90.,  71.],\n",
       "         [ 79.,  81.,  70.]],\n",
       "\n",
       "        [[140., 160., 169.],\n",
       "         [145., 153., 154.],\n",
       "         [125., 125., 118.],\n",
       "         ...,\n",
       "         [ 96.,  99.,  78.],\n",
       "         [ 77.,  80.,  62.],\n",
       "         [ 71.,  73.,  61.]],\n",
       "\n",
       "        [[140., 155., 164.],\n",
       "         [139., 146., 149.],\n",
       "         [115., 115., 112.],\n",
       "         ...,\n",
       "         [ 79.,  82.,  64.],\n",
       "         [ 68.,  70.,  55.],\n",
       "         [ 67.,  69.,  55.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[175., 167., 166.],\n",
       "         [156., 154., 160.],\n",
       "         [154., 160., 170.],\n",
       "         ...,\n",
       "         [ 42.,  34.,  36.],\n",
       "         [ 61.,  53.,  57.],\n",
       "         [ 93.,  83.,  91.]],\n",
       "\n",
       "        [[165., 154., 128.],\n",
       "         [156., 152., 130.],\n",
       "         [159., 161., 142.],\n",
       "         ...,\n",
       "         [103.,  93.,  96.],\n",
       "         [123., 114., 120.],\n",
       "         [131., 121., 131.]],\n",
       "\n",
       "        [[163., 148., 120.],\n",
       "         [158., 148., 122.],\n",
       "         [163., 156., 133.],\n",
       "         ...,\n",
       "         [143., 133., 139.],\n",
       "         [143., 134., 142.],\n",
       "         [143., 133., 144.]]],\n",
       "\n",
       "\n",
       "       [[[255., 255., 255.],\n",
       "         [253., 253., 253.],\n",
       "         [253., 253., 253.],\n",
       "         ...,\n",
       "         [253., 253., 253.],\n",
       "         [253., 253., 253.],\n",
       "         [253., 253., 253.]],\n",
       "\n",
       "        [[255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         ...,\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.],\n",
       "         [255., 255., 255.]],\n",
       "\n",
       "        [[255., 255., 255.],\n",
       "         [254., 254., 254.],\n",
       "         [254., 254., 254.],\n",
       "         ...,\n",
       "         [254., 254., 254.],\n",
       "         [254., 254., 254.],\n",
       "         [254., 254., 254.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[113., 120., 112.],\n",
       "         [111., 118., 111.],\n",
       "         [105., 112., 106.],\n",
       "         ...,\n",
       "         [ 72.,  81.,  80.],\n",
       "         [ 72.,  80.,  79.],\n",
       "         [ 72.,  80.,  79.]],\n",
       "\n",
       "        [[111., 118., 110.],\n",
       "         [104., 111., 104.],\n",
       "         [ 99., 106.,  98.],\n",
       "         ...,\n",
       "         [ 68.,  75.,  73.],\n",
       "         [ 70.,  76.,  75.],\n",
       "         [ 78.,  84.,  82.]],\n",
       "\n",
       "        [[106., 113., 105.],\n",
       "         [ 99., 106.,  98.],\n",
       "         [ 95., 102.,  94.],\n",
       "         ...,\n",
       "         [ 78.,  85.,  83.],\n",
       "         [ 79.,  85.,  83.],\n",
       "         [ 80.,  86.,  84.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 20.,  15.,  12.],\n",
       "         [ 19.,  14.,  11.],\n",
       "         [ 15.,  14.,  11.],\n",
       "         ...,\n",
       "         [ 10.,   9.,   7.],\n",
       "         [ 12.,  11.,   9.],\n",
       "         [ 13.,  12.,  10.]],\n",
       "\n",
       "        [[ 21.,  16.,  13.],\n",
       "         [ 20.,  16.,  13.],\n",
       "         [ 18.,  17.,  12.],\n",
       "         ...,\n",
       "         [ 10.,   9.,   7.],\n",
       "         [ 10.,   9.,   7.],\n",
       "         [ 12.,  11.,   9.]],\n",
       "\n",
       "        [[ 21.,  16.,  13.],\n",
       "         [ 21.,  17.,  12.],\n",
       "         [ 20.,  18.,  11.],\n",
       "         ...,\n",
       "         [ 12.,  11.,   9.],\n",
       "         [ 12.,  11.,   9.],\n",
       "         [ 13.,  12.,  10.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 33.,  25.,  13.],\n",
       "         [ 34.,  26.,  15.],\n",
       "         [ 34.,  26.,  15.],\n",
       "         ...,\n",
       "         [ 28.,  25.,  52.],\n",
       "         [ 29.,  25.,  58.],\n",
       "         [ 23.,  20.,  42.]],\n",
       "\n",
       "        [[ 33.,  25.,  14.],\n",
       "         [ 34.,  26.,  15.],\n",
       "         [ 34.,  26.,  15.],\n",
       "         ...,\n",
       "         [ 27.,  24.,  52.],\n",
       "         [ 27.,  24.,  56.],\n",
       "         [ 25.,  22.,  47.]],\n",
       "\n",
       "        [[ 31.,  23.,  12.],\n",
       "         [ 32.,  24.,  13.],\n",
       "         [ 33.,  25.,  14.],\n",
       "         ...,\n",
       "         [ 24.,  23.,  50.],\n",
       "         [ 26.,  23.,  53.],\n",
       "         [ 25.,  20.,  47.]]],\n",
       "\n",
       "\n",
       "       [[[ 25.,  40.,  12.],\n",
       "         [ 15.,  36.,   3.],\n",
       "         [ 23.,  41.,  18.],\n",
       "         ...,\n",
       "         [ 61.,  82.,  78.],\n",
       "         [ 92., 113., 112.],\n",
       "         [ 75.,  89.,  92.]],\n",
       "\n",
       "        [[ 12.,  25.,   6.],\n",
       "         [ 20.,  37.,   7.],\n",
       "         [ 24.,  36.,  15.],\n",
       "         ...,\n",
       "         [115., 134., 138.],\n",
       "         [149., 168., 177.],\n",
       "         [104., 117., 131.]],\n",
       "\n",
       "        [[ 12.,  25.,  11.],\n",
       "         [ 15.,  29.,   6.],\n",
       "         [ 34.,  40.,  24.],\n",
       "         ...,\n",
       "         [154., 172., 182.],\n",
       "         [157., 175., 192.],\n",
       "         [116., 129., 151.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[100., 129.,  81.],\n",
       "         [103., 132.,  84.],\n",
       "         [104., 134.,  86.],\n",
       "         ...,\n",
       "         [ 97., 128.,  84.],\n",
       "         [ 98., 126.,  84.],\n",
       "         [ 91., 121.,  79.]],\n",
       "\n",
       "        [[103., 132.,  83.],\n",
       "         [104., 131.,  83.],\n",
       "         [107., 135.,  87.],\n",
       "         ...,\n",
       "         [101., 132.,  87.],\n",
       "         [ 99., 127.,  84.],\n",
       "         [ 92., 121.,  79.]],\n",
       "\n",
       "        [[ 95., 126.,  78.],\n",
       "         [ 95., 123.,  76.],\n",
       "         [101., 128.,  81.],\n",
       "         ...,\n",
       "         [ 93., 124.,  80.],\n",
       "         [ 95., 123.,  81.],\n",
       "         [ 92., 120.,  80.]]],\n",
       "\n",
       "\n",
       "       [[[ 73.,  78.,  75.],\n",
       "         [ 98., 103., 113.],\n",
       "         [ 99., 106., 114.],\n",
       "         ...,\n",
       "         [135., 150., 152.],\n",
       "         [135., 149., 154.],\n",
       "         [203., 215., 223.]],\n",
       "\n",
       "        [[ 69.,  73.,  70.],\n",
       "         [ 84.,  89.,  97.],\n",
       "         [ 68.,  75.,  81.],\n",
       "         ...,\n",
       "         [ 85.,  95.,  89.],\n",
       "         [ 71.,  82.,  80.],\n",
       "         [120., 133., 135.]],\n",
       "\n",
       "        [[ 69.,  73.,  70.],\n",
       "         [ 90.,  95., 100.],\n",
       "         [ 62.,  71.,  74.],\n",
       "         ...,\n",
       "         [ 74.,  81.,  70.],\n",
       "         [ 53.,  62.,  54.],\n",
       "         [ 62.,  74.,  69.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[123., 128.,  96.],\n",
       "         [132., 132., 102.],\n",
       "         [129., 128., 100.],\n",
       "         ...,\n",
       "         [108., 107.,  88.],\n",
       "         [ 62.,  60.,  55.],\n",
       "         [ 27.,  27.,  28.]],\n",
       "\n",
       "        [[115., 121.,  91.],\n",
       "         [123., 124.,  95.],\n",
       "         [129., 126.,  99.],\n",
       "         ...,\n",
       "         [115., 116.,  94.],\n",
       "         [ 66.,  65.,  59.],\n",
       "         [ 27.,  27.,  27.]],\n",
       "\n",
       "        [[116., 120.,  90.],\n",
       "         [121., 122.,  94.],\n",
       "         [129., 128., 101.],\n",
       "         ...,\n",
       "         [116., 115.,  94.],\n",
       "         [ 68.,  65.,  58.],\n",
       "         [ 27.,  26.,  26.]]]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T13:54:02.784012Z",
     "start_time": "2025-05-20T13:54:01.801602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "encoder = create_encoder(representation_dims)\n",
    "representation_leaner = RepresentationLearner(\n",
    "    encoder, projection_units, num_augmentations=2, temperature=0.1\n",
    ")\n",
    "\n",
    "lr_scheduler = keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=0.001, decay_steps=500, alpha=0.1\n",
    ")\n",
    "\n"
   ],
   "id": "3002209d3d6e3e12",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T13:54:02.823654Z",
     "start_time": "2025-05-20T13:54:02.796221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "representation_leaner.compile(\n",
    "    optimizer=keras.optimizers.AdamW(\n",
    "        learning_rate=lr_scheduler, weight_decay=0.0001\n",
    "    ), jit_compile=False\n",
    ")\n"
   ],
   "id": "803741c8163090d9",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T14:21:18.249934Z",
     "start_time": "2025-05-20T13:54:02.847601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "history = representation_leaner.fit(\n",
    "    x=x_data,\n",
    "    batch_size=512,\n",
    "    epochs=50\n",
    ")"
   ],
   "id": "7bfe769279f7d86c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1747749264.772899   96941 cuda_dnn.cc:529] Loaded cuDNN version 90501\n",
      "2025-05-20 14:54:29.101259: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 8.02GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-05-20 14:54:29.101381: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 8.02GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-05-20 14:54:29.101392: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 8.02GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m62s\u001B[0m 290ms/step - loss: 155.9490\n",
      "Epoch 2/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 270ms/step - loss: 12.4564\n",
      "Epoch 3/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 273ms/step - loss: 11.6190\n",
      "Epoch 4/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m29s\u001B[0m 244ms/step - loss: 11.2777\n",
      "Epoch 5/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 275ms/step - loss: 11.1350\n",
      "Epoch 6/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 279ms/step - loss: 11.0130\n",
      "Epoch 7/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 280ms/step - loss: 10.9188\n",
      "Epoch 8/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 277ms/step - loss: 10.7847\n",
      "Epoch 9/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 279ms/step - loss: 10.7198\n",
      "Epoch 10/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 279ms/step - loss: 10.5968\n",
      "Epoch 11/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 279ms/step - loss: 10.9419\n",
      "Epoch 12/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 277ms/step - loss: 10.6128\n",
      "Epoch 13/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 276ms/step - loss: 10.4285\n",
      "Epoch 14/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m29s\u001B[0m 247ms/step - loss: 10.3064\n",
      "Epoch 15/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 279ms/step - loss: 10.3030\n",
      "Epoch 16/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 278ms/step - loss: 10.0531\n",
      "Epoch 17/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 275ms/step - loss: 9.9004\n",
      "Epoch 18/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 274ms/step - loss: 9.7224\n",
      "Epoch 19/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 276ms/step - loss: 9.6166\n",
      "Epoch 20/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 272ms/step - loss: 9.4303\n",
      "Epoch 21/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 278ms/step - loss: 9.2996\n",
      "Epoch 22/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 276ms/step - loss: 9.1639\n",
      "Epoch 23/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 273ms/step - loss: 8.9784\n",
      "Epoch 24/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m29s\u001B[0m 243ms/step - loss: 8.8273\n",
      "Epoch 25/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 275ms/step - loss: 8.7648\n",
      "Epoch 26/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 278ms/step - loss: 8.5663\n",
      "Epoch 27/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 276ms/step - loss: 8.4866\n",
      "Epoch 28/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 276ms/step - loss: 8.2778\n",
      "Epoch 29/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 268ms/step - loss: 8.1446\n",
      "Epoch 30/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 268ms/step - loss: 8.0033\n",
      "Epoch 31/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 269ms/step - loss: 8.0688\n",
      "Epoch 32/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 271ms/step - loss: 8.4327\n",
      "Epoch 33/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m29s\u001B[0m 243ms/step - loss: 7.8469\n",
      "Epoch 34/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 272ms/step - loss: 7.6607\n",
      "Epoch 35/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 271ms/step - loss: 7.5707\n",
      "Epoch 36/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 272ms/step - loss: 7.3546\n",
      "Epoch 37/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 277ms/step - loss: 7.4702\n",
      "Epoch 38/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 273ms/step - loss: 7.6627\n",
      "Epoch 39/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 277ms/step - loss: 7.4585\n",
      "Epoch 40/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 273ms/step - loss: 7.1618\n",
      "Epoch 41/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 278ms/step - loss: 7.0553\n",
      "Epoch 42/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m29s\u001B[0m 245ms/step - loss: 6.8804\n",
      "Epoch 43/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 275ms/step - loss: 6.7741\n",
      "Epoch 44/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 272ms/step - loss: 6.6263\n",
      "Epoch 45/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 276ms/step - loss: 6.8124\n",
      "Epoch 46/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 277ms/step - loss: 6.7602\n",
      "Epoch 47/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 273ms/step - loss: 7.0086\n",
      "Epoch 48/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m32s\u001B[0m 275ms/step - loss: 6.6610\n",
      "Epoch 49/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 278ms/step - loss: 6.4881\n",
      "Epoch 50/50\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 276ms/step - loss: 6.3530\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T14:21:18.702416Z",
     "start_time": "2025-05-20T14:21:18.591381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from graph import loss_graph, display_learning_curves\n",
    "\n",
    "loss_graph(history.history['loss'])"
   ],
   "id": "99cfd043a660a398",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAGwCAYAAACzXI8XAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAANHNJREFUeJzt3Xt0VPW99/HPJHPLbWZygVxIAigKqAUfUTFi2yNiOWqtHnmW1uNZ2qM+Llu0CtqLdlm1ntOw7FJbjoF6eljSrnUs9bLQRz1aESUePWA1wCMiRdCUBHPjkmRym8kks58/ZjIhEhAys/dmwvu11l6Z2Xuy88sW5ePv+7s4DMMwBAAAkIYy7G4AAADAWBFkAABA2iLIAACAtEWQAQAAaYsgAwAA0hZBBgAApC2CDAAASFtOuxtgtmg0qqamJuXl5cnhcNjdHAAAcAwMw1BXV5fKysqUkXHkfpdxH2SamppUUVFhdzMAAMAYNDY2qry8/IjXx32QycvLkxR7ED6fz+bWAACAYxEMBlVRUZH4e/xIxn2QGSon+Xw+ggwAAGnmq4aFMNgXAACkLYIMAABIWwQZAACQtggyAAAgbRFkAABA2iLIAACAtEWQAQAAaYsgAwAA0hZBBgAApC2CDAAASFsEGQAAkLYIMgAAIG2N+00jzdLZF1GwL6I8r1OBbLfdzQEA4KREj8wY/fLVHfr6o2/rP99vsLspAACctAgyY+RxxR5dODJoc0sAADh5EWTGyOOMB5mBqM0tAQDg5EWQGSOPM1MSQQYAADsRZMZouEeG0hIAAHYhyIzR8BgZemQAALALQWaMKC0BAGA/gswYUVoCAMB+BJkx8rrokQEAwG4EmTFK9MgwRgYAANsQZMYoMdiX0hIAALYhyIwRg30BALAfQWaMWNkXAAD7EWTGKNEjw15LAADYhiAzRsNjZOiRAQDALrYGmYceekgOh2PEMWPGjMT1UCikxYsXq7CwULm5uVq0aJFaW1ttbPEwSksAANjP9h6ZM888U83NzYnj3XffTVxbsmSJXn75ZT333HOqra1VU1OTrrnmGhtbO2x4sC+lJQAA7OK0vQFOp0pKSg4739nZqVWrVumZZ57R/PnzJUlPP/20Zs6cqU2bNumCCy4Y9X7hcFjhcDjxPhgMmtLuoR6ZyKChwaihzAyHKT8HAAAcme09Mrt27VJZWZlOOeUU3XDDDWpoaJAk1dXVKRKJaMGCBYnPzpgxQ5WVldq4ceMR71ddXS2/3584KioqTGn30BgZiV4ZAADsYmuQmTt3rlavXq3XX39dK1euVH19vb7+9a+rq6tLLS0tcrvdCgQCI76nuLhYLS0tR7znfffdp87OzsTR2NhoStvdmYcEGVb3BQDAFraWli677LLE61mzZmnu3LmaPHmynn32WWVlZY3pnh6PRx6PJ1VNPCJnZoacGQ4NRA0G/AIAYBPbS0uHCgQCOv3007V7926VlJSov79fHR0dIz7T2to66pgaO7ADNgAA9jqhgkx3d7c+++wzlZaWas6cOXK5XFq/fn3i+s6dO9XQ0KCqqiobWznMww7YAADYytbS0r333qsrr7xSkydPVlNTkx588EFlZmbq+uuvl9/v1y233KKlS5eqoKBAPp9Pd955p6qqqo44Y8lq7IANAIC9bA0ye/fu1fXXX68DBw5owoQJuuiii7Rp0yZNmDBBkvTEE08oIyNDixYtUjgc1sKFC7VixQo7mzwCpSUAAOxla5BZs2bNUa97vV7V1NSopqbGohYdH3bABgDAXifUGJl0M7zfEj0yAADYgSCTBMbIAABgL4JMEigtAQBgL4JMEhjsCwCAvQgySfCyjgwAALYiyCSBMTIAANiLIJMEZi0BAGAvgkwSGOwLAIC9CDJJGB7sS5ABAMAOBJkkDI+RobQEAIAdCDJJYPdrAADsRZBJAqUlAADsRZBJAgviAQBgL4JMEhKzllhHBgAAWxBkkjC8jgxBBgAAOxBkkjBUWgoxawkAAFsQZJLAgngAANiLIJMEBvsCAGAvgkwSGCMDAIC9CDJJYNYSAAD2IsgkgdISAAD2IsgkgcG+AADYiyCTBMbIAABgL4JMEoZKS4NRQwODhBkAAKxGkEnCUGlJolcGAAA7EGSS4HYOPz6CDAAA1iPIJCEzwyFXpkMSM5cAALADQSZJXtaSAQDANgSZJDFzCQAA+xBkkjS8lgylJQAArEaQSdLw6r70yAAAYDWCTJKGZi4xRgYAAOsRZJLkcVFaAgDALgSZJFFaAgDAPgSZJLEDNgAA9iHIJMnDOjIAANiGIJMk1pEBAMA+BJkkUVoCAMA+BJkkDZWWQpSWAACwHEEmSfTIAABgH4JMkhJjZOiRAQDAcgSZJA3vtUSQAQDAagSZJFFaAgDAPgSZJLGyLwAA9iHIJCmx1xJjZAAAsBxBJkmUlgAAsA9BJkmUlgAAsA9BJknMWgIAwD4EmSQN77VEaQkAAKsRZJKUKC0x2BcAAMsRZJLkdVFaAgDALgSZJDFrCQAA+xBkksRgXwAA7EOQSRJjZAAAsA9BJkmHzloyDMPm1gAAcHIhyCRpqLQUNaSBKEEGAAArEWSSNFRakhgnAwCA1QgySRoRZCLMXAIAwEoEmSQ5HA652W8JAABbEGRSgI0jAQCwB0EmBYbXkqG0BACAlQgyKTDUIxNiLRkAACx1wgSZZcuWyeFw6O67706cC4VCWrx4sQoLC5Wbm6tFixaptbXVvkYeQWItGQb7AgBgqRMiyHzwwQd66qmnNGvWrBHnlyxZopdfflnPPfecamtr1dTUpGuuucamVh4Z2xQAAGAP24NMd3e3brjhBv3ud79Tfn5+4nxnZ6dWrVqlxx9/XPPnz9ecOXP09NNP63/+53+0adOmI94vHA4rGAyOOMzGYF8AAOxhe5BZvHixrrjiCi1YsGDE+bq6OkUikRHnZ8yYocrKSm3cuPGI96uurpbf708cFRUVprV9CDtgAwBgD1uDzJo1a7R582ZVV1cfdq2lpUVut1uBQGDE+eLiYrW0tBzxnvfdd586OzsTR2NjY6qbfRiPK15aYrAvAACWctr1gxsbG3XXXXdp3bp18nq9Kbuvx+ORx+NJ2f2O6WdSWgIAwBa29cjU1dWpra1N55xzjpxOp5xOp2pra7V8+XI5nU4VFxerv79fHR0dI76vtbVVJSUl9jT6CCgtAQBgD9t6ZC655BJt27ZtxLl//ud/1owZM/STn/xEFRUVcrlcWr9+vRYtWiRJ2rlzpxoaGlRVVWVHk4+IWUsAANjDtiCTl5ens846a8S5nJwcFRYWJs7fcsstWrp0qQoKCuTz+XTnnXeqqqpKF1xwgR1NPqLhdWQIMgAAWMm2IHMsnnjiCWVkZGjRokUKh8NauHChVqxYYXezDkNpCQAAe5xQQWbDhg0j3nu9XtXU1KimpsaeBh0jSksAANjD9nVkxgOvix4ZAADsQJBJgUSPDGNkAACwFEEmBVhHBgAAexBkUsBDaQkAAFsQZFKAwb4AANiDIJMCidISY2QAALAUQSYFWEcGAAB7EGRSILH7NaUlAAAsRZBJAWYtAQBgD4JMClBaAgDAHgSZFGBBPAAA7EGQSYGhdWRCEXpkAACwEkEmBRgjAwCAPQgyKXDogniGYdjcGgAATh4EmRQYKi1JUv8gvTIAAFiFIJMCQ6UlifISAABWIsikgDvzkCDDzCUAACxDkEkBh8PBWjIAANiAIJMizFwCAMB6BJkUSey3RGkJAADLEGRShNISAADWI8ikCKUlAACsR5BJkUMXxQMAANYgyKSIN74oXpj9lgAAsAxBJkXokQEAwHoEmRQZ2qaAIAMAgHUIMinCrCUAAKxHkEmRRGmJdWQAALAMQSZFmH4NAID1CDIpMjxGhtISAABWIcikCLOWAACwHkEmRRKlJcbIAABgGYJMigz3yFBaAgDAKgSZFGEdGQAArEeQSRFmLQEAYD2CTIoMlZZC7LUEAIBlCDIpQo8MAADWI8ikiIfdrwEAsBxBJkVYRwYAAOsRZFKE0hIAANYjyKQIu18DAGA9gkyKeFzsfg0AgNUIMilCaQkAAOsRZFKE0hIAANYjyKRIorREjwwAAJYhyKTIUI9M/0BUhmHY3BoAAE4OBJkU8cZ7ZCR6ZQAAsApBJkWGemQkggwAAFYhyKSIM8OhDEfsNQN+AQCwBkEmRRwOx/A2BawlAwCAJQgyKZTYOJLSEgAAliDIpBBryQAAYC2CTAqxAzYAANYiyKRQokeGMTIAAFiCIJNCw2NkKC0BAGAFgkwKUVoCAMBaBJkUYgdsAACsRZBJoeExMpSWAACwAkEmhYZKSyF6ZAAAsARBJoUSg33pkQEAwBIEmRRijAwAANYaU5D5/e9/r1dffTXx/sc//rECgYAuvPBC7dmzJ2WNSzfMWgIAwFpjCjK//OUvlZWVJUnauHGjampq9Oijj6qoqEhLliw55vusXLlSs2bNks/nk8/nU1VVlV577bXE9VAopMWLF6uwsFC5ublatGiRWltbx9JkS7BFAQAA1hpTkGlsbNS0adMkSS+++KIWLVqk2267TdXV1frv//7vY75PeXm5li1bprq6On344YeaP3++rrrqKm3fvl2StGTJEr388st67rnnVFtbq6amJl1zzTVjabIlhsfI0CMDAIAVnGP5ptzcXB04cECVlZV64403tHTpUkmS1+tVX1/fMd/nyiuvHPH+X//1X7Vy5Upt2rRJ5eXlWrVqlZ555hnNnz9fkvT0009r5syZ2rRpky644IJR7xkOhxUOhxPvg8Hg8f56Y0ZpCQAAa42pR+bSSy/VrbfeqltvvVWffvqpLr/8cknS9u3bNWXKlDE1ZHBwUGvWrFFPT4+qqqpUV1enSCSiBQsWJD4zY8YMVVZWauPGjUe8T3V1tfx+f+KoqKgYU3vGgtISAADWGlOQqampUVVVlfbt26cXXnhBhYWFkqS6ujpdf/31x3Wvbdu2KTc3Vx6PR7fffrvWrl2rM844Qy0tLXK73QoEAiM+X1xcrJaWliPe77777lNnZ2fiaGxsPO7fb6yYtQQAgLXGVFoKBAJ68sknDzv/8MMPH/e9pk+frq1bt6qzs1PPP/+8brrpJtXW1o6lWZIkj8cjj8cz5u9PhscVLy0xRgYAAEuMqUfm9ddf17vvvpt4X1NTo7PPPlv/+I//qPb29uO6l9vt1rRp0zRnzhxVV1dr9uzZ+s1vfqOSkhL19/ero6NjxOdbW1tVUlIylmabzsvu1wAAWGpMQeZHP/pRYhDttm3bdM899+jyyy9XfX19YuDvWEWjUYXDYc2ZM0cul0vr169PXNu5c6caGhpUVVWV1M8wC4N9AQCw1phKS/X19TrjjDMkSS+88IK+/e1v65e//KU2b96cGPh7LO677z5ddtllqqysVFdXl5555hlt2LBBf/7zn+X3+3XLLbdo6dKlKigokM/n05133qmqqqojzliyG2NkAACw1piCjNvtVm9vryTpzTff1I033ihJKigoOK7pzm1tbbrxxhvV3Nwsv9+vWbNm6c9//rMuvfRSSdITTzyhjIwMLVq0SOFwWAsXLtSKFSvG0mRLJHpk2GsJAABLjCnIXHTRRVq6dKnmzZunv/zlL/rTn/4kSfr0009VXl5+zPdZtWrVUa97vV7V1NSopqZmLM203NCCeP30yAAAYIkxjZF58skn5XQ69fzzz2vlypWaNGmSJOm1117T3//936e0gemE0hIAANYaU49MZWWlXnnllcPOP/HEE0k3KJ0ND/altAQAgBXGFGSk2Eq8L774onbs2CFJOvPMM/Wd73xHmZmZKWtcukn0yLCODAAAlhhTkNm9e7cuv/xyffHFF5o+fbqk2NYAFRUVevXVV3XqqaemtJHpIrFpJKUlAAAsMaYxMj/84Q916qmnqrGxUZs3b9bmzZvV0NCgqVOn6oc//GGq25g2hkpL/YNRRaOGza0BAGD8G1OPTG1trTZt2qSCgoLEucLCQi1btkzz5s1LWePSzVBpSYqFGW/GyVtmAwDACmPqkfF4POrq6jrsfHd3t9xud9KNSleHBhnGyQAAYL4xBZlvf/vbuu222/T+++/LMAwZhqFNmzbp9ttv13e+851UtzFtODMzlJnhkMTMJQAArDCmILN8+XKdeuqpqqqqktfrldfr1YUXXqhp06bp17/+dYqbmF6GemVC9MgAAGC6MY2RCQQCeumll7R79+7E9OuZM2dq2rRpKW1cOvI4M9TbP0iPDAAAFjjmIPNVu1q//fbbidePP/742FuU5mIzlyJMwQYAwALHHGS2bNlyTJ9zOBxjbsx4MLyWDD0yAACY7ZiDzKE9LjgyVvcFAMA6YxrsiyMb3m+JIAMAgNkIMik2vAM2pSUAAMxGkEkx9lsCAMA6BJkUS5SWGCMDAIDpCDIpRmkJAADrEGRSzOtisC8AAFYhyKTYcI8MQQYAALMRZFJseB0ZSksAAJiNIJNiHkpLAABYhiCTYpSWAACwDkEmxZi1BACAdQgyKcY6MgAAWIcgk2Ks7AsAgHUIMilGaQkAAOsQZFKM3a8BALAOQSbFhteRIcgAAGA2gkyKDY+RobQEAIDZCDIpRmkJAADrEGRSbKi0FGKLAgAATEeQSTF6ZAAAsA5BJsVYRwYAAOsQZFKM3a8BALAOQSbFKC0BAGAdgkyKDfXIDEQNDQwSZgAAMBNBJsWGxshIUj9BBgAAUxFkUsydOfxIWd0XAABzEWRSzJmZIWeGQxLjZAAAMBtBxgTsgA0AgDUIMibwupi5BACAFQgyJmAHbAAArEGQMYEn0SNDaQkAADMRZEwwPEaGHhkAAMxEkDEBg30BALAGQcYEiW0KGCMDAICpCDImYAdsAACsQZAxAaUlAACsQZAxATtgAwBgDYKMCVhHBgAAaxBkTDA8RobSEgAAZiLImIDSEgAA1iDImIAF8QAAsAZBxgTDY2QoLQEAYCaCjAmG9loKMdgXAABTEWRMwDoyAABYgyBjAsbIAABgDYKMCZi1BACANQgyJmAdGQAArEGQMQEr+wIAYA1bg0x1dbXOO+885eXlaeLEibr66qu1c+fOEZ8JhUJavHixCgsLlZubq0WLFqm1tdWmFh8bSksAAFjD1iBTW1urxYsXa9OmTVq3bp0ikYi+9a1vqaenJ/GZJUuW6OWXX9Zzzz2n2tpaNTU16ZprrrGx1V+NWUsAAFjDaecPf/3110e8X716tSZOnKi6ujp94xvfUGdnp1atWqVnnnlG8+fPlyQ9/fTTmjlzpjZt2qQLLrjAjmZ/peExMvTIAABgphNqjExnZ6ckqaCgQJJUV1enSCSiBQsWJD4zY8YMVVZWauPGjaPeIxwOKxgMjjisligtMUYGAABTnTBBJhqN6u6779a8efN01llnSZJaWlrkdrsVCARGfLa4uFgtLS2j3qe6ulp+vz9xVFRUmN30w3iZtQQAgCVOmCCzePFiffzxx1qzZk1S97nvvvvU2dmZOBobG1PUwmPHYF8AAKxh6xiZIXfccYdeeeUVvfPOOyovL0+cLykpUX9/vzo6Okb0yrS2tqqkpGTUe3k8Hnk8HrObfFSs7AsAgDVs7ZExDEN33HGH1q5dq7feektTp04dcX3OnDlyuVxav3594tzOnTvV0NCgqqoqq5t7zIZ6ZAajhgYGCTMAAJjF1h6ZxYsX65lnntFLL72kvLy8xLgXv9+vrKws+f1+3XLLLVq6dKkKCgrk8/l05513qqqq6oSdsSQNz1qSYr0yzswTpoIHAMC4YmuQWblypSTp7/7u70acf/rpp/W9731PkvTEE08oIyNDixYtUjgc1sKFC7VixQqLW3p83Jkjg0yOvZUuAADGLVuDjGEYX/kZr9ermpoa1dTUWNCi1MjIcMidmaH+wSgzlwAAMBE1D5Ow3xIAAOYjyJiE1X0BADAfQcYkw2vJUFoCAMAsBBmTsJYMAADmI8iYxM0YGQAATEeQMYnHRWkJAACzEWRMMlRaCtEjAwCAaQgyJhkeI0OPDAAAZiHImIQdsAEAMB9BxiSJdWQi9MgAAGAWgoxJmH4NAID5CDImobQEAID5CDImYbAvAADmI8iYZHiMDD0yAACYhSBjEkpLAACYjyBjEq+L0hIAAGYjyJiEHhkAAMxHkDGJh00jAQAwHUHGJMxaAgDAfAQZkwzvfk2PDAAAZiHImISVfQEAMB9BxiSUlgAAMB9BxiSJWUsM9gUAwDQEGZMkVvaltAQAgGkIMiahtAQAgPkIMiZhQTwAAMxHkDEJC+IBAGA+goxJPIfstWQYhs2tAQBgfCLImGSotBQ1pIEoQQYAADMQZEwyVFqSpFCEAb8AAJiBIGOSQ4MMA34BADAHQcYkDodDbrYpAADAVAQZEw3PXKK0BACAGQgyJmItGQAAzEWQMRE7YAMAYC6CjIkSa8lQWgIAwBQEGRNRWgIAwFwEGRN52QEbAABTEWRMxA7YAACYiyBjokRpiY0jAQAwBUHGRMxaAgDAXAQZE3lcQ4N9KS0BAGAGgoyJ6JEBAMBcBBkTDW9RQJABAMAMBBkTDa8jQ2kJAAAzEGRM5GEdGQAATEWQMRHryAAAYC6CjIlYRwYAAHMRZEzErCUAAMxFkDGRN76OzDu79uk/39+jgUECDQAAqUSQMdE3Ti/S1KIcdfRG9LO1H2vhr9/Ruk9aZRiG3U0DAGBccBjj/G/VYDAov9+vzs5O+Xw+y39+/0BUz7y/R8vf2q2DPf2SpPOnFuj+y2fq7IqA5e0BACAdHOvf3wQZq9oRiui3Gz7TqnfrE2NmrphVqh8vnK7JhTm2tQsAgBMRQSbuRAkyQ5o7+/TYG5/qhc17ZRiSK9Ohf7pgsv7P109RWSDL7uYBAHBCIMjEnWhBZsgnTUEte/2veufTfYlzZX6v/tfkfJ1Tma//VRnQmWW+xBRuAABOJgSZuBM1yAz571379Os3d2lLQ7uiX/on4XZm6Kwyn86pzNc5k/N1RqlPJX5vYjYUAADjFUEm7kQPMkO6wwP6qLFDWxo7tHlPuzY3tKu9NzLqZwty3Cr2eVXq96rE71WpL/7Vn6Vin0dFuR4Fsl1yOBwW/xYAAKQGQSYuXYLMlxmGob8d6NXmPe3a0tiuzXs69Pn+boWOcZVgZ4ZDhbluFeV6ho88tybEXxfmulWYE/takOOWK5OZ+ACAEwdBJi5dg8xoDMNQZ19EzZ0htXSG1BIMxV/3qbkzpNZg7HwwNHDc9/ZnueLhZjjgFOV6NCHvkCP+3o7SlmEYCg9EKasBwEniWP/+dlrYJiTJ4XAokO1WINutmaVH/ocaHhjUge5+7e8Ox46ufu0bet3dr/1dYR3s6deBntjXqCF19kXU2RfR5/t6vrIdeR6nJuR5VJTnUX62S/6s2OHzuuTPjn/NcsmX5ZI/yymvK3NEmevQgtfQ6XAkqtZgSK1dYbUOhbJgSG3BsFq7Yu9DkajK/F6dUebXmWW+2DHJrzK/lzIaAJyk6JE5yQ1GY708B7rDOtDTrwPdsYCzPx6E9nXFjv3dYbV1hdV/Au4bFch2xYNNLOBMm5irqUU5ynaT0wEgXVFaiiPIpI5hGOoKDyTCzb6usDp6+xUMDcR6dHojCoYiid6dYCh2LnRo+DEOfTn8xpmRoWKfRxN9XpX4vCr2eVTs8yaOEp9XOZ5M7Wrr1idNQW1vCmp7U6d2t3Vr4MvTveJK/V5NLcpJHKdMyNHUolyV52cxJggATnBpEWTeeecd/epXv1JdXZ2am5u1du1aXX311YnrhmHowQcf1O9+9zt1dHRo3rx5WrlypU477bRj/hkEmfEtFBnUrtZubW/q1PamoD5pDurzfd1HnPElxQZCF+V65Mtyyud1Kc/rlC9eGhs654uXywLZLuVnxwZEB7JdrOsDABZJizEyPT09mj17tm6++WZdc801h11/9NFHtXz5cv3+97/X1KlT9cADD2jhwoX65JNP5PV6bWgxTjReV6a+Vu7X18r9I8639/Sr/kCP6vf1qH5/7Ph8f4/q4zO/WoIhtQSP/+dluzOVn+1Wfk4s4BTlelRZkK2pRTmaUpSjqYU58me7UvTbAQC+yglTWnI4HCN6ZAzDUFlZme655x7de++9kqTOzk4VFxdr9erV+u53v3tM96VHBoeKRg21doV0oLtfwXj5K9g3EP8aUTA0kDjf0RtRe2+/Onoj6uiLaPAIJawvy892JULN5MIcTSnK1uTCHFXkZ6kgx83AZAA4BmnRI3M09fX1amlp0YIFCxLn/H6/5s6dq40bNx4xyITDYYXD4cT7YHAM/9uNcSsjw6FSf5ZK/ce3r1U0aqgrNKD23v7hoyei1q6Q9uzvVf2BHv1tf4/ausJq742ovaFDWxo6DrtPtjtTlQXZKs/PVmVBtioKslSRn63KwmxNCmQpx3PC/isJACekE/a/mi0tLZKk4uLiEeeLi4sT10ZTXV2thx9+2NS24eSTkeGQPzs2vXyKjrxbeU94QH870KM9B3pVvz8Wbv52oEeNB/vU2hVSb/+g/trSpb+2dI36/f4slyYFslQWyNKkgFdl8dex91makOdRZgY9OgAw5IQNMmN13333aenSpYn3wWBQFRUVNrYIJ5McjzM+Ddx/2LVQZFBfdPSp8WBv7GjvU8OBXjW296rhYK+6hmZ/9UX0SfPoPYnODIeKfV6VBWJbUpQGvCrzZ6nUHws9pX4v5SsAJ5UTNsiUlJRIklpbW1VaWpo439raqrPPPvuI3+fxeOTxeMxuHnDcvK5MnTohV6dOyB31ejAUUXNHSE0dffqio09NiSOkLzr61BIMaSBq6Iv4dal91PtkuTJVnp+lioLseBkrK17Gih25lK8AjCMn7H/Rpk6dqpKSEq1fvz4RXILBoN5//319//vft7dxgAl8Xpd8JS5NL8kb9frAYFT7usNq6gipubMvFno6Y2GnuTOkpo6Q9neH1RcZ1K62bu1q6x71PgU5bpXnD/filMV7dkr9WSoLeDUxz0v5CkDasDXIdHd3a/fu3Yn39fX12rp1qwoKClRZWam7775b//Iv/6LTTjstMf26rKxsxFozwMnCmZlxyEDl/FE/Ex4YVHNHKFGuajzYp8b23kQ5q703ooM9/TrY06+P9naOeo/MDIeK8zwqDRwadrwqPST0FFK+AnCCsHX69YYNG3TxxRcfdv6mm27S6tWrEwvi/fu//7s6Ojp00UUXacWKFTr99NOP+Wcw/RoY1hWKqPFgn/a298Z6ceI9O82dsRJWa7x89VU8zgyV+ofH6ZT6vSrxZ6nU51WJ38tYHQBJS4uVfa1AkAGO3WDU0P7usL7oGBlwmuMlrKbOkPZ1hb/6RpLc8bBT4vNqUiBL5flZKs/PVnl8ynmJ38tWEQCOKO3XkQFgvcz4rKhin1eqHP0z/QOxncpjwSY2PqelMzTi6/7u2Aajew70as+B3lHvk+GQSv3DAWdSfNzOUI9Oic8rf5aLXh0AR0WQAXBc3M6MxAyoIwkPDKotGFZzZ6w354uOPu1tHzp6tbe9T/0D0cQMrPfrD456H68rNi6oxOdNhJzKguzELKxSv1dOenWAkxpBBkDKeZyZRw070XgJq/GQYNPU0TfcsxMM6WBPv0KRaGKvrNE4MxyaFJ9eXpmYbp6tghy3/FmxBQwDWS5luzPp2QHGKYIMAMtlZDg00efVRJ9XcyaPPgMrFBlUa3BkyeqLjvhMrIPxXp3Bo5evhjgzHApkH7KreZZLk/KzdEpRrk6ZkKNTinI1KT+LaedAGiLIADgheV2ZmhzfeHM0g1FDrcGQGg4OTTWPfd3b3qeO3n519g2os69fkUFDA1FD+7v7tb+7/4g/z+3M0JTC2E7mp0zI1dSinMSg5BKfV1nuTLN+1a/UPxDV7rZufb6/W9OL83Ra8ehrDQEnI2YtARi3DMNQX2RQHb2RxPYPHb0RdfT2a8/BXtXv69Hn+7v1twO96h+IHvVeeV6nSuIDoYt9XpX4PSr2xRYQnOjzaGKeRxPyPPI4kws8B3v6taM5qB3NQX3SHNSO5i7tbutSZHD4P9Wzyv1adE65vjO7TPk57qR+HnCiYvp1HEEGwFcZjBpq6ujT5/t79Pm+bn2+LzYupym+NURv/+Ax3yuQ7dKEXE883Hg1Mc8jf7ZLg4OG+gej6h+IDn8diCoyGHvfFRrQp61dag2OPr09z+vUlMIc7WgOJtb6cWU6dMmMYi2aU66/mz6B6ewYVwgycQQZAMkwDEPd4QG1BkNq6QzHvgZjiwfGjrD2dcWO/sGj9+ocq8mF2ZpZ4tPMUp9mluZpZqlP5flZcjgc2t8d1v/d2qTn6/aO2Fy0MMetq86epP89p1xnlPHfOqQ/gkwcQQaAFQzDUGdfRG1dYbUFw2rrCqktHnA6+yJyZWbInemQ25kRex3/6ol/zXJl6tSJOZpe4jvmjT13NAf1Qt1evbj1ixHjf4py3ZqY59WEvFjJ69DeoaHXE/I88rrsG/cDfBWCTBxBBsB4FxmM6p1P9+mFzXv15idtx9wzlOd1akKuR0V5Hk3IjY3xKcp1a0J8vM/EPK+mTcw1PfAYhqHwQFTuzAxlMHMMcQSZOIIMgJNJVyiiPQd6ta8r3isUDGtf98heorau8FcObh6S4ZCmFOZoekmeppfkaUZJnqaX+FRZkD3qdPVgKBJb9bkjtr3F0PpAwdCA+iID6u0fVF//oHrjR1//gPoig4oaI2eOTSnK0SlFOZpaFJtBVpTL3l0nG4JMHEEGAEYyDEPBvgHt6w5rf3es/PXlr/u6w/qivU/tvZFR7+F1Zej04jxNLcpRR28ksS9Xd3jAlDbneZyaUpSjyYWxhRYr8rNVnp+lioJslQW8Sc8Ww4mHIBNHkAGAsTEMQ/u6w9rZ0qWdLV3a0dylna1B7WrtVvgoPTr52S6V+rNUFsjSpEBsZ/RAdmyFZa8rU9nu2JHlciZee92Z6uyN6PP9ParfF5sS//n+HtXv79be9j4d7W8qh0MqzvOqoiC+MWl+VmzBxbyhKfKxUhmzutILQSaOIAMAqTUYNfS3Az3a2dKlPQd6VZjjVmnAq7JAbOPPbHdq11oNDwyq8WCvPtvXo8b44odD21s0HuxTX+Srp8c7HFJBtjsRcEp8Xk0uytapE3J16oQcVRbkyO08MYNONGpoV1u3PtxzUH9t7lJ+dmxl6lhQjH0djwO3CTJxBBkAGL8Mw9CBnn7tbR/euuKLjl61BcNq7QprXzA2Lmho7Z0jycxwqLIgW6cU5ejUibmJr6V+r4pyrZ3h1ds/oP/X2Km6PQf14Z52bd7TrmDo6CW7olyPJuVnqTyQpUn5WTqzzKfzphSoLJBlUatTjyATR5ABgJNbNGqovbdfrcHhAdDNnSHV7+/WZ/tiiyD2fMWih3kep4ris7qKEjO8YkdBjlv52S7l57gVyHYpkOU+au/O0FT92Hikfh3oCWt/V1h7Dvaqbk+7PmkKHha8st2ZOrsioK+V+9UVGtAX8Y1Wv+joO+qCjeX5WTp/SoHOn1qg86YW6JSinLQZNE2QiSPIAACOxjAMtQbD+nxftz7bFws3n+3rVv3+HrUFx7bQYY47U4Fst/JzXMrPdiszI7aY4f54cDl0y4nRlPpjG6qeOzlf504p0IySPDlHGeNjGIY6eiP6oqMv3hsV65na0tCuj5uCGvxSICrKdeu8eLA5a5JfFfnZmpjnOSGnvRNk4ggyAICx+vIMr1gYCWt/d39iltfB3n519EbU3tuvzr7IUQcmH8rnHerlia3jU+zzanaFX+dOKdCkFJSEusMD2tLQrr/UH9T79Qe1tbFj1Gn3rkyHygJZKs/PUnkgNli6PD5wuiyQpeI8z6ghymwEmTiCDADAKoNRQ8G+WKjp6IttUNreE9Fg1FBRnjtRjirMdVs+ZTw8MKiP9nbqL/UH9cHfDuqzfd1q6ggd1mvzZRkOaWKeVyV+r8oCXpX4smJf/V6V+mMDvCeaEHYIMnEEGQAARjcwGFVrV1h74wOl98Zng+1t79Pejl41d4S+cqC0JN1/+Qzd9o1TU9q2Y/37O7Vz5AAAQNpwZmZoUnwa99xRrkejhvZ3xwZHN3f2xb/Gj47Y+9ZgSKV++2ZHEWQAAMCoMjIcsbV3fF7NrgiM+pnBqKGojcUdggwAABizzAyHMmXfrKcTcxlDAACAY0CQAQAAaYsgAwAA0hZBBgAApC2CDAAASFsEGQAAkLYIMgAAIG0RZAAAQNoiyAAAgLRFkAEAAGmLIAMAANIWQQYAAKQtggwAAEhb4373ayO+tXgwGLS5JQAA4FgN/b099Pf4kYz7INPV1SVJqqiosLklAADgeHV1dcnv9x/xusP4qqiT5qLRqJqampSXlyeHw5Gy+waDQVVUVKixsVE+ny9l98XoeN7W4nlbj2duLZ63tcbyvA3DUFdXl8rKypSRceSRMOO+RyYjI0Pl5eWm3d/n8/EvgYV43tbieVuPZ24tnre1jvd5H60nZgiDfQEAQNoiyAAAgLRFkBkjj8ejBx98UB6Px+6mnBR43tbieVuPZ24tnre1zHze436wLwAAGL/okQEAAGmLIAMAANIWQQYAAKQtggwAAEhbBJkxqqmp0ZQpU+T1ejV37lz95S9/sbtJ48I777yjK6+8UmVlZXI4HHrxxRdHXDcMQz//+c9VWlqqrKwsLViwQLt27bKnseNAdXW1zjvvPOXl5WnixIm6+uqrtXPnzhGfCYVCWrx4sQoLC5Wbm6tFixaptbXVphant5UrV2rWrFmJRcGqqqr02muvJa7zrM2zbNkyORwO3X333YlzPO/Ueuihh+RwOEYcM2bMSFw363kTZMbgT3/6k5YuXaoHH3xQmzdv1uzZs7Vw4UK1tbXZ3bS019PTo9mzZ6umpmbU648++qiWL1+u3/72t3r//feVk5OjhQsXKhQKWdzS8aG2tlaLFy/Wpk2btG7dOkUiEX3rW99ST09P4jNLlizRyy+/rOeee061tbVqamrSNddcY2Or01d5ebmWLVumuro6ffjhh5o/f76uuuoqbd++XRLP2iwffPCBnnrqKc2aNWvEeZ536p155plqbm5OHO+++27immnP28BxO//8843Fixcn3g8ODhplZWVGdXW1ja0afyQZa9euTbyPRqNGSUmJ8atf/SpxrqOjw/B4PMYf//hHG1o4/rS1tRmSjNraWsMwYs/X5XIZzz33XOIzO3bsMCQZGzdutKuZ40p+fr7xH//xHzxrk3R1dRmnnXaasW7dOuOb3/ymcddddxmGwZ9tMzz44IPG7NmzR71m5vOmR+Y49ff3q66uTgsWLEicy8jI0IIFC7Rx40YbWzb+1dfXq6WlZcSz9/v9mjt3Ls8+RTo7OyVJBQUFkqS6ujpFIpERz3zGjBmqrKzkmSdpcHBQa9asUU9Pj6qqqnjWJlm8eLGuuOKKEc9V4s+2WXbt2qWysjKdcsopuuGGG9TQ0CDJ3Oc97jeNTLX9+/drcHBQxcXFI84XFxfrr3/9q02tOjm0tLRI0qjPfugaxi4ajeruu+/WvHnzdNZZZ0mKPXO3261AIDDiszzzsdu2bZuqqqoUCoWUm5urtWvX6owzztDWrVt51im2Zs0abd68WR988MFh1/iznXpz587V6tWrNX36dDU3N+vhhx/W17/+dX388cemPm+CDABJsf9z/fjjj0fUtJF606dP19atW9XZ2annn39eN910k2pra+1u1rjT2Niou+66S+vWrZPX67W7OSeFyy67LPF61qxZmjt3riZPnqxnn31WWVlZpv1cSkvHqaioSJmZmYeNtG5tbVVJSYlNrTo5DD1fnn3q3XHHHXrllVf09ttvq7y8PHG+pKRE/f396ujoGPF5nvnYud1uTZs2TXPmzFF1dbVmz56t3/zmNzzrFKurq1NbW5vOOeccOZ1OOZ1O1dbWavny5XI6nSouLuZ5mywQCOj000/X7t27Tf3zTZA5Tm63W3PmzNH69esT56LRqNavX6+qqiobWzb+TZ06VSUlJSOefTAY1Pvvv8+zHyPDMHTHHXdo7dq1euuttzR16tQR1+fMmSOXyzXime/cuVMNDQ088xSJRqMKh8M86xS75JJLtG3bNm3dujVxnHvuubrhhhsSr3ne5uru7tZnn32m0tJSc/98JzVU+CS1Zs0aw+PxGKtXrzY++eQT47bbbjMCgYDR0tJid9PSXldXl7FlyxZjy5YthiTj8ccfN7Zs2WLs2bPHMAzDWLZsmREIBIyXXnrJ+Oijj4yrrrrKmDp1qtHX12dzy9PT97//fcPv9xsbNmwwmpubE0dvb2/iM7fffrtRWVlpvPXWW8aHH35oVFVVGVVVVTa2On399Kc/NWpra436+nrjo48+Mn76058aDofDeOONNwzD4Fmb7dBZS4bB8061e+65x9iwYYNRX19vvPfee8aCBQuMoqIio62tzTAM8543QWaM/u3f/s2orKw03G63cf755xubNm2yu0njwttvv21IOuy46aabDMOITcF+4IEHjOLiYsPj8RiXXHKJsXPnTnsbncZGe9aSjKeffjrxmb6+PuMHP/iBkZ+fb2RnZxv/8A//YDQ3N9vX6DR28803G5MnTzbcbrcxYcIE45JLLkmEGMPgWZvty0GG551a1113nVFaWmq43W5j0qRJxnXXXWfs3r07cd2s5+0wDMNIrk8HAADAHoyRAQAAaYsgAwAA0hZBBgAApC2CDAAASFsEGQAAkLYIMgAAIG0RZAAAQNoiyAAAgLRFkAFw0tmwYYMcDsdhG9gBSD8EGQAAkLYIMgAAIG0RZABYLhqNqrq6WlOnTlVWVpZmz56t559/XtJw2efVV1/VrFmz5PV6dcEFF+jjjz8ecY8XXnhBZ555pjwej6ZMmaLHHntsxPVwOKyf/OQnqqiokMfj0bRp07Rq1aoRn6mrq9O5556r7OxsXXjhhdq5c6e5vziAlCPIALBcdXW1/vCHP+i3v/2ttm/friVLluif/umfVFtbm/jMj370Iz322GP64IMPNGHCBF155ZWKRCKSYgHk2muv1Xe/+11t27ZNDz30kB544AGtXr068f033nij/vjHP2r58uXasWOHnnrqKeXm5o5ox89+9jM99thj+vDDD+V0OnXzzTdb8vsDSB12vwZgqXA4rIKCAr355puqqqpKnL/11lvV29ur2267TRdffLHWrFmj6667TpJ08OBBlZeXa/Xq1br22mt1ww03aN++fXrjjTcS3//jH/9Yr776qrZv365PP/1U06dP17p167RgwYLD2rBhwwZdfPHFevPNN3XJJZdIkv7rv/5LV1xxhfr6+uT1ek1+CgBShR4ZAJbavXu3ent7demllyo3Nzdx/OEPf9Bnn32W+NyhIaegoEDTp0/Xjh07JEk7duzQvHnzRtx33rx52rVrlwYHB7V161ZlZmbqm9/85lHbMmvWrMTr0tJSSVJbW1vSvyMA6zjtbgCAk0t3d7ck6dVXX9WkSZNGXPN4PCPCzFhlZWUd0+dcLlfitcPhkBQbvwMgfdAjA8BSZ5xxhjwejxoaGjRt2rQRR0VFReJzmzZtSrxub2/Xp59+qpkzZ0qSZs6cqffee2/Efd977z2dfvrpyszM1Ne+9jVFo9ERY24AjE/0yACwVF5enu69914tWbJE0WhUF110kTo7O/Xee+/J5/Np8uTJkqRf/OIXKiwsVHFxsX72s5+pqKhIV199tSTpnnvu0XnnnadHHnlE1113nTZu3Kgnn3xSK1askCRNmTJFN910k26++WYtX75cs2fP1p49e9TW1qZrr73Wrl8dgAkIMgAs98gjj2jChAmqrq7W559/rkAgoHPOOUf3339/orSzbNky3XXXXdq1a5fOPvtsvfzyy3K73ZKkc845R88++6x+/vOf65FHHlFpaal+8Ytf6Hvf+17iZ6xcuVL333+/fvCDH+jAgQOqrKzU/fffb8evC8BEzFoCcEIZmlHU3t6uQCBgd3MAnOAYIwMAANIWQQYAAKQtSksAACBt0SMDAADSFkEGAACkLYIMAABIWwQZAACQtggyAAAgbRFkAABA2iLIAACAtEWQAQAAaev/A9CUItPu5+//AAAAAElFTkSuQmCC"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T15:21:26.039485Z",
     "start_time": "2025-05-20T15:20:45.240490Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "projection = representation_leaner.predict(x_data)\n"
   ],
   "id": "533850a042042db8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m37s\u001B[0m 20ms/step\n"
     ]
    }
   ],
   "execution_count": 127
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T15:30:58.154804Z",
     "start_time": "2025-05-20T15:30:46.664561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "k = 5\n",
    "knns = NearestNeighbors(n_neighbors=k+1, algorithm='auto').fit(projection)\n",
    "distances, indices = knns.kneighbors(projection)"
   ],
   "id": "47b7887b6581ee34",
   "outputs": [],
   "execution_count": 137
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T15:31:52.343059Z",
     "start_time": "2025-05-20T15:31:52.313555Z"
    }
   },
   "cell_type": "code",
   "source": "indices",
   "id": "68eb6816670978ea",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     0,  70496,  64676,  22804,   4689,  20181],\n",
       "       [     1,  13337,  91396,  40827,  13369,  17756],\n",
       "       [     2, 104538,  41997,  82827,  77147,  84016],\n",
       "       ...,\n",
       "       [119997,  89127, 106128,  77450,  67751,  15429],\n",
       "       [119998,   9302,   1940,  40203,  44882,  39384],\n",
       "       [119999,  83204,  38896,  48296,  99217,  57537]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 138
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T15:29:27.226465Z",
     "start_time": "2025-05-20T15:29:27.202604Z"
    }
   },
   "cell_type": "code",
   "source": "projection",
   "id": "b33d1fa822b470da",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01447856, 0.2829877 , 0.04519387, ..., 0.69105804, 0.        ,\n",
       "        0.04005024],\n",
       "       [0.21771632, 0.27387902, 0.13415672, ..., 0.13187245, 0.06541857,\n",
       "        0.04522827],\n",
       "       [0.17537044, 0.28668934, 0.24449176, ..., 0.0842534 , 0.44731054,\n",
       "        0.46608296],\n",
       "       ...,\n",
       "       [0.06623831, 0.06757492, 0.15641783, ..., 0.        , 0.26086757,\n",
       "        0.19897047],\n",
       "       [0.16860959, 0.06240962, 0.        , ..., 0.0305047 , 0.12097736,\n",
       "        0.08266789],\n",
       "       [0.06713383, 0.02033253, 0.33428746, ..., 0.        , 0.52892196,\n",
       "        0.07149306]], dtype=float32)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 133
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "node_features = torch.tensor(projection, dtype=torch.float)\n",
    "indices = torch.tensor(indices, dtype=torch.long)\n",
    "\n",
    "\n",
    "num_nodes, k = indices.shape\n",
    "sources = np.repeat(np.arange(num_nodes), k)\n",
    "targets = indices.flatten()\n",
    "\n",
    "sources = torch.from_numpy(sources)\n",
    "\n",
    "edge_index = torch.stack([sources, targets], dim=0)"
   ],
   "id": "851d2d7c78e4c7a3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96722/3513593915.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  indices = torch.tensor(indices, dtype=torch.long)\n"
     ]
    }
   ],
   "execution_count": 155
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T15:39:06.957725Z",
     "start_time": "2025-05-20T15:39:06.931075Z"
    }
   },
   "cell_type": "code",
   "source": "edge_index",
   "id": "db4c396263b54203",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     0,  70496,  64676,  ...,  48296,  99217,  57537],\n",
       "        [     0,      0,      0,  ..., 119999, 119999, 119999]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 154
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T15:35:32.767081Z",
     "start_time": "2025-05-20T15:35:32.737758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_geometric.data import Data\n",
    "data = Data(x=node_features, edge_index=edge_index)"
   ],
   "id": "4ddb80c226d30f63",
   "outputs": [],
   "execution_count": 142
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T15:35:32.812969Z",
     "start_time": "2025-05-20T15:35:32.788213Z"
    }
   },
   "cell_type": "code",
   "source": "data.edge_index",
   "id": "e6b6b72cda7048bd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     0,      0,      0,  ..., 119999, 119999, 119999],\n",
       "        [     0,  70496,  64676,  ...,  48296,  99217,  57537]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 143
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_nodes = data.num_nodes\n",
    "\n",
    "train_ratio, val_ratio = 0.8, 0.1\n",
    "nun_train = int(num_nodes * train_ratio)\n",
    "nun_val = int(num_nodes * val_ratio)\n",
    "\n",
    "perm = torch.randperm(num_nodes)\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "train_mask[perm[:nun_train]] = True\n",
    "val_mask[perm[nun_train : nun_train + nun_val]] = True\n",
    "test_mask[perm[nun_train + nun_val :]] = True\n",
    "\n",
    "data.train_mask = train_mask\n",
    "data.val_mask = val_mask\n",
    "data.test_mask = test_mask"
   ],
   "id": "86167d81e7c4c026",
   "outputs": [],
   "execution_count": 144
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T15:35:58.471517Z",
     "start_time": "2025-05-20T15:35:58.444498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, feature_dim, hidden_dim, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(feature_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return x\n",
    "\n"
   ],
   "id": "fec2c2530cb3d613",
   "outputs": [],
   "execution_count": 145
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T15:35:58.518510Z",
     "start_time": "2025-05-20T15:35:58.491785Z"
    }
   },
   "cell_type": "code",
   "source": "model = GCN(feature_dim=node_features.shape[1], hidden_dim=16, num_classes=num_classes)",
   "id": "7043e3108cefdf74",
   "outputs": [],
   "execution_count": 146
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T15:35:58.563935Z",
     "start_time": "2025-05-20T15:35:58.541594Z"
    }
   },
   "cell_type": "code",
   "source": "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)",
   "id": "331488578269ccd7",
   "outputs": [],
   "execution_count": 147
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T15:35:58.616535Z",
     "start_time": "2025-05-20T15:35:58.592639Z"
    }
   },
   "cell_type": "code",
   "source": "model.train()",
   "id": "2963e917f758447d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (conv1): GCNConv(128, 16)\n",
       "  (conv2): GCNConv(16, 10)\n",
       ")"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 148
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T15:35:58.666364Z",
     "start_time": "2025-05-20T15:35:58.642957Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def contrastive_loss(z1, z2, temperature=0.5):\n",
    "    z1 = F.normalize(z1, dim=1)\n",
    "    z2 = F.normalize(z2, dim=1)\n",
    "    similarity_matrix = torch.mm(z1, z2.t()) / temperature\n",
    "    labels = torch.arange(z1.size(0)).to(z1.device)\n",
    "    return F.cross_entropy(similarity_matrix, labels)"
   ],
   "id": "2256546694a8611c",
   "outputs": [],
   "execution_count": 149
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T15:35:58.715068Z",
     "start_time": "2025-05-20T15:35:58.691873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import grafog.transforms as T\n",
    "\n",
    "node_aug = T.Compose([\n",
    "    T.NodeDrop(p=0.2),\n",
    "    T.NodeFeatureMasking(p=0.15),\n",
    "])\n",
    "\n",
    "edge_aug = T.Compose([\n",
    "    T.EdgeDrop(p=0.1),\n",
    "])\n",
    "\n",
    "def augment_graph(data):\n",
    "    new_data = node_aug(data)\n",
    "    new_data = edge_aug(new_data)\n",
    "    return new_data"
   ],
   "id": "37b07daa69f15b0c",
   "outputs": [],
   "execution_count": 150
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T15:35:58.786932Z",
     "start_time": "2025-05-20T15:35:58.741614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch_geometric.transforms as T\n",
    "data = T.ToSparseTensor()(data)"
   ],
   "id": "7f2f909b063fdb59",
   "outputs": [],
   "execution_count": 151
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T15:35:58.880953Z",
     "start_time": "2025-05-20T15:35:58.802255Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    data1 = augment_graph(data)\n",
    "    data2 = augment_graph(data)\n",
    "\n",
    "    z1 = model(data1)\n",
    "    z2 = model(data2)\n",
    "\n",
    "    loss = contrastive_loss(z1, z2)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "\n",
    "\n"
   ],
   "id": "a8aedab08da0e6e9",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'permute'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[152], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m200\u001B[39m):\n\u001B[1;32m      2\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m----> 4\u001B[0m     data1 \u001B[38;5;241m=\u001B[39m \u001B[43maugment_graph\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m     data2 \u001B[38;5;241m=\u001B[39m augment_graph(data)\n\u001B[1;32m      7\u001B[0m     z1 \u001B[38;5;241m=\u001B[39m model(data1)\n",
      "Cell \u001B[0;32mIn[150], line 14\u001B[0m, in \u001B[0;36maugment_graph\u001B[0;34m(data)\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21maugment_graph\u001B[39m(data):\n\u001B[1;32m     13\u001B[0m     new_data \u001B[38;5;241m=\u001B[39m node_aug(data)\n\u001B[0;32m---> 14\u001B[0m     new_data \u001B[38;5;241m=\u001B[39m \u001B[43medge_aug\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnew_data\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     15\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m new_data\n",
      "File \u001B[0;32m~/.virtualenvs/machine_learning/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/machine_learning/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/.virtualenvs/machine_learning/lib/python3.10/site-packages/grafog/transforms/transforms.py:13\u001B[0m, in \u001B[0;36mCompose.forward\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, data):\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m aug \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransforms:\n\u001B[0;32m---> 13\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[43maug\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[0;32m~/.virtualenvs/machine_learning/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/machine_learning/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/.virtualenvs/machine_learning/lib/python3.10/site-packages/grafog/transforms/transforms.py:47\u001B[0m, in \u001B[0;36mEdgeDrop.forward\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m     44\u001B[0m test_mask \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mtest_mask\n\u001B[1;32m     45\u001B[0m edge_idx \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39medge_index\n\u001B[0;32m---> 47\u001B[0m edge_idx \u001B[38;5;241m=\u001B[39m \u001B[43medge_idx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpermute\u001B[49m(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m     48\u001B[0m idx \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mempty(edge_idx\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m))\u001B[38;5;241m.\u001B[39muniform_(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     49\u001B[0m edge_idx \u001B[38;5;241m=\u001B[39m edge_idx[torch\u001B[38;5;241m.\u001B[39mwhere(idx \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mp)]\u001B[38;5;241m.\u001B[39mpermute(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0\u001B[39m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'permute'"
     ]
    }
   ],
   "execution_count": 152
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
